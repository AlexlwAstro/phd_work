{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions, modules done\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "#%matplotlib notebook\n",
    "#%pylab\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import fileinput\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import CubicSpline\n",
    "import scipy.special as scs\n",
    "from scipy.stats import norm\n",
    "import operator\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colorbar as cobar\n",
    "\n",
    "# Change font sizes to makes figure legends and axes labels bigger\n",
    "# NOTE: 10 pt is the default standard font size\n",
    "plt.rc('axes', labelsize=16)    # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=16)    # legend fontsize\n",
    "\n",
    "# function to change OUTPUT file into space-separated float fields and parameterise the data using this new format\n",
    "# line in 'with open' bit is type 'str'\n",
    "\n",
    "# create a function to get spectral grid data\n",
    "\n",
    "oldstr = ['0-','1-','2-','3-','4-','5-','6-','7-','8-','9-']\n",
    "newstr = ['0 -','1 -','2 -','3 -','4 -','5 -','6 -','7 -','8 -','9 -']\n",
    "\n",
    "def data_read_gaia(f):\n",
    "    # GENERAL PYTHON DATA READ FUNCTION!!!\n",
    "    missed_line_inds = []\n",
    "    temp_data = []\n",
    "    check = 0\n",
    "    #number of lines to cut = number of line containing 'convective shell' label - (2 + any additional string lines)\n",
    "    for line in f:\n",
    "        for i in range(len(oldstr)):\n",
    "            line = line.replace(oldstr[i],newstr[i])\n",
    "        check = check + 1\n",
    "        for x in range(10,1,-1):\n",
    "            line = line.replace((x*' '),' ')\n",
    "        line = line.replace('D','E')\n",
    "        match_ast = re.search('[**]', line)\n",
    "        match_inf = re.search('Infinity',line)\n",
    "        match_hash = re.search('#',line)\n",
    "        if match_ast or match_inf or match_hash or (line.strip()==''):\n",
    "            missed_line_inds.append(check)\n",
    "        else:\n",
    "            file_data = np.array([float(parameter) for parameter in line.strip().split(' ')])\n",
    "            temp_data.append(file_data)\n",
    "    out_all_data = np.array(temp_data)\n",
    "\n",
    "    print 'Total dataset: ',out_all_data.shape\n",
    "    return out_all_data\n",
    "\n",
    "# select the parameter (Teff or log(g) for each array(file)) with which to analyse the filter profiles,\n",
    "# by setting the other to be constant, using the column number (integer)\n",
    "def grid_vals_dict(input_arr,col_numb):\n",
    "    col_vals = []\n",
    "    col_var_arrs = {}\n",
    "    # create list of values of the column NOT being examined\n",
    "    for i in range(len(input_arr[:,(col_numb - 1)])):\n",
    "        if (input_arr[i,(col_numb - 1)] not in col_vals):\n",
    "            col_vals.append(input_arr[i,(col_numb - 1)])\n",
    "    print 'Table column ',col_numb,' values list: ',col_vals\n",
    "    # create arrays for fixed values of col_numb parameter\n",
    "    for j in col_vals:\n",
    "        temp_k_list = []\n",
    "        for k in range(len(input_arr[:,(col_numb - 1)])):\n",
    "            if (input_arr[k,(col_numb - 1)] == j):\n",
    "                temp_k_list.append(input_arr[k,:])\n",
    "        temp_k_array = np.array(temp_k_list)\n",
    "        #print 'For column',col_numb,'value of',j,', the array has the following shape: ',temp_k_array.shape\n",
    "        col_var_arrs[str(j)] = temp_k_array\n",
    "    print 'Final dictionary length: ',len(col_var_arrs)\n",
    "    return col_var_arrs\n",
    "\n",
    "   \n",
    "def diff_grid_dict(dict_Av0,dict_Avne0):\n",
    "    diff_dict = {}\n",
    "    # use sets to match keys in dictionaries\n",
    "    combined_set = set(dict_Av0).intersection(set(dict_Avne0))\n",
    "    print 'combined set size:',len(combined_set)\n",
    "    for key_val in combined_set:\n",
    "        #print key_val\n",
    "        # use variables to store each key value\n",
    "        Av0_arr_kv = dict_Av0[key_val]\n",
    "        Avne0_arr_kv = dict_Avne0[key_val]\n",
    "        # take the difference of the two sets of filter magnitudes for different calibrations of BCs\n",
    "        # gives absolute extinction A(X) as numerical output\n",
    "        diff_arr_kv = Av0_arr_kv - Avne0_arr_kv\n",
    "        for n in range(len(diff_arr_kv[0,:])):\n",
    "            if (n == 0 or n == 1):\n",
    "                # these columns are Teff, log(g) - the inputs for the grid - need to reset these to recover grid\n",
    "                diff_arr_kv[:,n] = Av0_arr_kv[:,n]\n",
    "        diff_dict[key_val] = diff_arr_kv\n",
    "        if (diff_arr_kv.shape != Avne0_arr_kv.shape):\n",
    "            print 'shape error'\n",
    "    print 'Raw A(X) dictionary complete'\n",
    "    return diff_dict\n",
    "\n",
    "\n",
    "# general fits write-out function\n",
    "\n",
    "def general_fit_number_gen_write(f,func_type,func_coeffs,covar_matrix,filter_str,logg_val,avg_dict):\n",
    "    frac_list = []\n",
    "    output_names = ['    Fit coefficients (in order of functions'' arguments):','    Standard deviations:']\n",
    "    f.write('Fitting results for ' + str(filter_str) + ' filter, with log(g) = ' + str(logg_val) + '\\n')\n",
    "    f.write('Function type:  ' + func_type + '\\n')\n",
    "    f.write(output_names[0] + '\\n')\n",
    "    f.write(str(func_coeffs) + '\\n')\n",
    "    f.write(output_names[1] + '\\n')\n",
    "    f.write(str(covar_matrix) + '\\n')\n",
    "    f.write('Fractional errors in fit coefficients = {E[(X(i)-E[X(i)])*(X(j)-E[X(j)])]}/{|E[X(i)]*E[X(j)]|}' + '\\n')\n",
    "    f.write('i.e., covariance(i,j)/{coef(i)*coef(j)}' + 2*'\\n')\n",
    "    f.write('Fractional error output:  ' + '\\n')\n",
    "    # write out errors as detailed above\n",
    "    \n",
    "    sum_y = 0\n",
    "    yterm_count = 0\n",
    "    for i in range(len(func_coeffs)):\n",
    "        f.write('row ' + str(i+1) + 2*'\\t')\n",
    "        # use if statement to avoid repeating terms in symmetrical covariance matrix\n",
    "        # should result in increasing number of entries for increasing row number\n",
    "        y = abs(covar_matrix[i]/func_coeffs[i])\n",
    "        f.write(str(y) + '\\t')\n",
    "        yterm_count += 1\n",
    "        sum_y += y\n",
    "        f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    avg_y = sum_y/yterm_count\n",
    "    avg_dict[func_type] = avg_y\n",
    "    f.write('Average fractional error = ' + str(avg_y) + 2*'\\n')\n",
    "    print 'Average fractional error for ' + func_type + ' = ' + str(avg_y)\n",
    "    \n",
    "# Modelling functions below!!!\n",
    "\n",
    "# linear function\n",
    "def linear_func(xdata,a,b):\n",
    "    y = (a*xdata) + b\n",
    "    return y\n",
    "\n",
    "# quadratic function\n",
    "def quad_func(xdata,a,b,c):\n",
    "    y = a*(xdata**2) + (b*xdata) + c\n",
    "    return y\n",
    "\n",
    "# single power-law term\n",
    "def single_poly(xdata,a,b,c):\n",
    "    y = a*((1.0e-04*xdata)**b) + c\n",
    "    return y\n",
    "\n",
    "# exponential function\n",
    "def exp_func(xdata,a,b,c):\n",
    "    y = a*(np.exp(b*(1.0e-04*xdata))) + c\n",
    "    return y\n",
    "\n",
    "# logarithmic function\n",
    "def log_func(xdata,a,b,c):\n",
    "    y = (a*(np.log10(b*xdata))) + c\n",
    "    return y\n",
    "\n",
    "# Teff & logg quadratic-like function\n",
    "# Need y = 0 at Teff cut-off value -> put (Tcut-Tdata) at front\n",
    "def Teff_logg_product_func(Tdata,Tcut,gdata,ind,a,b,c): #,d\n",
    "    y = ((Tcut-Tdata)**ind)*(a*(5.0-gdata)**b) + c #*(5.0-gdata)**(b-1)) + d\n",
    "    return y\n",
    "\n",
    "#polyfit_coeffs,polyfit_cov = (Tdata-Tcut),Aratio_data,deg\n",
    "\n",
    "# try to get compensatory functions\n",
    "# To avoid non-convergence\n",
    "def Teff_logg_polynomial(Tdata,Tcut,gdata,a,b,c=0.0,d=2):\n",
    "    # note: want b (power) to be integer!\n",
    "    y = ((a*(Tcut-Tdata)**d + b*(Tcut-Tdata)**(d-1))*(5.0-gdata)) + c\n",
    "    return y\n",
    "\n",
    "# Teff, metallicity & logg quadratic-like function\n",
    "def Teff_logg_metal_product_func(Tdata,gdata,metal_val,a,b,c=0.0,d=2):\n",
    "    # assuming Zsolar = 0.0172\n",
    "    y = ((a*(Tcut-Tdata)**d + b*(Tcut-Tdata)**(d-1))*(5.0-gdata)) + c\n",
    "    #y = a*(Tdata*gdata) + b*(gdata**2) + c + d*((0.0172 - metal_val)*Tdata)\n",
    "    return y\n",
    "\n",
    "# Full addition of exponential function to power-law\n",
    "def full_pow_plus_exp_func(xdata,a,b,c,d,e):\n",
    "    y = (d*(xdata**e)) + (a*(np.exp(b*xdata))) + c\n",
    "    return y\n",
    "\n",
    "\"\"\"\n",
    "maybe use underdamped oscillation as solution? With log(g), Z related to the value of the damping ratio, G?\n",
    "For underdamped systems, 0 < G < 1\n",
    "Approach: change in Ax/Av, call x, has solution x = C*exp(st)\n",
    "where s = -w_n * (G +/- i*sqrt(1 - G^2))\n",
    "NumPy: 'j' is the character used for imaginary numbers\n",
    "\"\"\"\n",
    "# PROBLEM: if zeta2**2 > 1, gives nan rather than evaluating two imaginary numbers!\n",
    "# Note: General solution is linear sum of terms!\n",
    "def decay_coeff_nan_avoid(omega,zeta,RIF=1.0):\n",
    "    if (abs(zeta) <= 1.0):\n",
    "        s1 = -omega*( zeta + RIF*1.0j*np.sqrt(1-zeta**2) ) #r*\n",
    "        s2 = -omega*( zeta - RIF*1.0j*np.sqrt(1-zeta**2) )\n",
    "    else:\n",
    "        s1 = -omega*( zeta - RIF*np.sqrt((zeta**2) - 1) ) #r* #r*\n",
    "        s2 = -omega*( zeta + RIF*np.sqrt((zeta**2) - 1) )\n",
    "    return s1,s2\n",
    "\n",
    "\n",
    "# low-Teff: log(g) affects A(filter)/A(V), i.e. A(Teff) becomes A(Teff,log(g))\n",
    "# -> find law for log(g) effects\n",
    "# N.B.: log(g) = consts. x (M(R*)/(R*)^2)\n",
    "# Linear? Girardi et al. (2008) use giant Teff law: Teff(log(g)) = 3250 + 500log(g)\n",
    "# For my values of log(g) (= 0 to 5), this gives a range of (3250 <= Teff <= 5750)\n",
    "# Take our working definition of 0.01 'error' as a limit on log(g) effects\n",
    "\n",
    "\n",
    "# need to combine some effects of Teff, log(g)\n",
    "# use Teff-keyed dictionaries as the dataset\n",
    "def from_keys_get_numerical_data(input_dict):\n",
    "    key_vals_list = []\n",
    "    for key in sorted(input_dict.iterkeys()):\n",
    "        float_key = float(key)\n",
    "        key_vals_list.append(float_key)\n",
    "    \n",
    "    key_vals_arr = np.array(key_vals_list)\n",
    "    print 'Array of key values: ', key_vals_arr.shape\n",
    "    return key_vals_arr\n",
    "\n",
    "\n",
    "# try a function to reduce oppportunities for error for stuff below\n",
    "# during curve fitting - tests, plots & writes out figure, writes out results of covariance matrix analysis\n",
    "\n",
    "# define the actual load-up of the functions to be fitted separately\n",
    "def functions_loadup(function,x_coords_fit,y_coords_fit,bounds_list,coeffs_list,stdev_list,sigma_val,abs_sig='n',p0_opt=None,niter=10000):\n",
    "    # functions_list, bounds_list MUST MATCH in their orders!! (functions and coefficient bounds, respectively)\n",
    "    #for a in functions_list: # iterate between function types\n",
    "    \n",
    "    ab_s_val = False\n",
    "    if (abs_sig != 'n'):\n",
    "        ab_s_val = True\n",
    "    if (sigma_val is not None):\n",
    "        sigmas = np.full(len(x_coords_fit),sigma_val)\n",
    "    else:\n",
    "        sigmas = None\n",
    "    function_coeffs,covarr = curve_fit(function,x_coords_fit,y_coords_fit, p0=p0_opt, sigma=sigmas,bounds=bounds_list,\\\n",
    "                                       absolute_sigma=ab_s_val,max_nfev=niter)\n",
    "    # extract the standard deviation\n",
    "    stdev = np.sqrt(np.diag(covarr))\n",
    "    \n",
    "    coeffs_list.append(function_coeffs)\n",
    "    # cov_arr_list.append(covarr)\n",
    "    stdev_list.append(stdev)\n",
    "    return coeffs_list,stdev_list #,cov_arr_list\n",
    "\n",
    "# Function to extract (unique) values of Ax/Av to place in a 2D-grid system\n",
    "def one_filter_get_grid(inarr,filter_column,Teff_grid,Teff_grid_vals,logg_grid,logg_grid_vals,grids_list,zero_fill='y'):\n",
    "    p = 0\n",
    "    if (zero_fill == 'y'):\n",
    "        Afilter_grid = np.zeros((len(Teff_grid_vals),len(logg_grid_vals)))\n",
    "    else:\n",
    "        Afilter_grid = np.full((len(Teff_grid_vals),len(logg_grid_vals)),np.nan)\n",
    "        #(max(inarr[:,filter_column])+0.00001)\n",
    "        \n",
    "    # Iterate through the grid elements, [i,j]\n",
    "    for i in range(len(Teff_grid[:,0])):\n",
    "        for j in range(len(logg_grid[0,:])):\n",
    "            T_i = Teff_grid[i,0]\n",
    "            g_j = logg_grid[0,j]\n",
    "            # go through the input Ax/Av array [k,x]\n",
    "            for k in range(len(inarr[:,0])):\n",
    "                T_k = inarr[k,0]\n",
    "                g_k = inarr[k,1]\n",
    "                # find matching Teff-log(g) pairs to keep Ax/Av data in the right place\n",
    "                if ( T_i == T_k and g_j == g_k ):\n",
    "                    p += 1\n",
    "                    Afilter_grid[i,j] = np.copy(inarr[k,filter_column])\n",
    "    Afilter_grid = np.around(Afilter_grid,decimals=5)\n",
    "    #print Afilter_grid[0,:]\n",
    "    grids_list.append(Afilter_grid)\n",
    "    return p\n",
    "\n",
    "def TgZ_2D_grid_plot(xgrid,ygrid,Afilters_list,details,z_Tcut_specifiers,fig_size):\n",
    "    fig,conax = plt.subplots(nrows=4,ncols=4,figsize=(fig_size, fig_size))\n",
    "    conax = conax.ravel()\n",
    "\n",
    "    cmap = cm.viridis # set colormap\n",
    "    #norm = plt.Normalize(min(np.amin(x) for x in Afilters_list),max(np.amax(x) for x in Afilters_list))\n",
    "\n",
    "    # NOTE: can treat conax[i] as with any other canvas!\n",
    "    for i in range(len(Afilters_list)):\n",
    "        #max_abs = max(abs(np.amin(Afilters_list[i])),abs(np.amax(Afilters_list[i])))\n",
    "        #norm = plt.Normalize(-max_abs,max_abs)\n",
    "        norm = plt.Normalize(np.amin(Afilters_list[i]),np.amax(Afilters_list[i]))\n",
    "        cont_i = conax[i].contourf(xgrid,ygrid,Afilters_list[i],cmap=cmap,norm=norm)\n",
    "        cbar = plt.colorbar(cont_i,ax=conax[i])\n",
    "        cbar.set_label(var_names_comb[i+2] + ' - $A_{1}(T_{eff})$')\n",
    "        #fig.colorbar(cont_i, ax=conax[i])\n",
    "        conax[i].set_xlim(4500,15000)\n",
    "        fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(details + z_Tcut_specifiers + '.pdf')\n",
    "    print 'Figure saved!'\n",
    "\n",
    "# curve fitting function\n",
    "def filter_curve_fit(dict_chosen,key,exp_bounds,pow_bounds,logis_bounds,plog_bounds,filter_str,sigma_value=None,abs_sigma_yn='n',p0_opt_logis=None,p0_opt_plog=None,niter=10000):\n",
    "    A_X_chosen = dict_chosen[key]\n",
    "    if (key == '5.0'):\n",
    "        # curve-fitting commands - for log(g) = 5.0 ONLY - apply results to other log(g) values\n",
    "        # store using the following lists:\n",
    "        exp_fit_A_logg5_list = []\n",
    "        stdev_A_logg5_ef_list = []\n",
    "        pow_fit_A_logg5_list = []\n",
    "        stdev_A_logg5_pow_list = []\n",
    "        # add logistic fit\n",
    "        logis_fit_A_logg5_list = []\n",
    "        stdev_A_logg5_logis_list = []\n",
    "        # add power-law logistic fit\n",
    "        plog_fit_A_logg5_list = []\n",
    "        stdev_A_logg5_plog_list = []\n",
    "        \n",
    "        exp_comb5_fits_dict = {}\n",
    "        exp_comb5_stdev_dict = {}\n",
    "        pow_comb5_fits_dict = {}\n",
    "        pow_comb5_stdev_dict = {}\n",
    "        logis_comb5_fits_dict = {}\n",
    "        logis_comb5_stdev_dict = {}\n",
    "        plog_comb5_fits_dict = {}\n",
    "        plog_comb5_stdev_dict = {}\n",
    "        \n",
    "        # *** NOTE: 'functions_loadup' is where curve_fit is employed ***\n",
    "        for i in range(2,len(A_X_chosen[0,:])):\n",
    "            functions_loadup(exp_func,A_X_chosen[:,0],A_X_chosen[:,i],exp_bounds[i-2],exp_fit_A_logg5_list,stdev_A_logg5_ef_list,sigma_value,abs_sigma_yn,niter=niter)\n",
    "            functions_loadup(single_poly,A_X_chosen[:,0],A_X_chosen[:,i],pow_bounds[i-2],pow_fit_A_logg5_list,stdev_A_logg5_pow_list,sigma_value,abs_sigma_yn,niter=niter)\n",
    "            functions_loadup(R1_logistic_func,A_X_chosen[:,0],A_X_chosen[:,i],logis_bounds[i-2],logis_fit_A_logg5_list,stdev_A_logg5_logis_list,sigma_value,abs_sigma_yn,p0_opt=p0_opt_logis,niter=niter)\n",
    "            functions_loadup(R1_log_normal_func,A_X_chosen[:,0],A_X_chosen[:,i],plog_bounds[i-2],plog_fit_A_logg5_list,stdev_A_logg5_plog_list,sigma_value,abs_sigma_yn,p0_opt=p0_opt_plog,niter=niter)\n",
    "            \n",
    "            #exp_fit_A_logg5, covarr_A_logg5_ef = curve_fit(exp_func,A_X_chosen[:,0],A_X_chosen[:,i], p0=None, sigma=None,bounds=exp_bounds[i-2])\n",
    "            #pow_fit_A_logg5, covarr_A_logg5_pow = curve_fit(single_poly,A_X_chosen[:,0],A_X_chosen[:,i], p0=None, sigma=None,bounds=pow_bounds[i-2])\n",
    "            #spp_exp_fit_A_logg5, covarr_A_logg5_spp = curve_fit(single_poly_plus_exp_func,A_X_chosen[:,0],A_X_chosen[:,i], p0=None, sigma=None,bounds=spp_bounds[i-2])\n",
    "\n",
    "            exp_fit_A_logg5 = exp_fit_A_logg5_list[i-2]\n",
    "            stdev_A_logg5_ef = stdev_A_logg5_ef_list[i-2]\n",
    "            pow_fit_A_logg5 = pow_fit_A_logg5_list[i-2]\n",
    "            stdev_A_logg5_pow = stdev_A_logg5_pow_list[i-2]\n",
    "            logis_fit_A_logg5 = logis_fit_A_logg5_list[i-2]\n",
    "            stdev_A_logg5_logis = stdev_A_logg5_logis_list[i-2]\n",
    "            plog_fit_A_logg5 = plog_fit_A_logg5_list[i-2]\n",
    "            stdev_A_logg5_plog = stdev_A_logg5_plog_list[i-2]\n",
    "            \n",
    "            # print fitting results\n",
    "            print 'Calculating coefficients & covariance matrices for ' + filter_str[i-2] + ' filter'\n",
    "            \n",
    "            print 'Exponential fit coefficients: '\n",
    "            print exp_fit_A_logg5\n",
    "            print 'Standard deviations: '\n",
    "            print stdev_A_logg5_ef\n",
    "            \n",
    "            exp_comb5_fits_dict[filter_str[i-2]] = exp_fit_A_logg5\n",
    "            exp_comb5_stdev_dict[filter_str[i-2]] = stdev_A_logg5_ef\n",
    "            \n",
    "            print 'Teff^(n) fit coefficients: '\n",
    "            print pow_fit_A_logg5\n",
    "            print 'Standard deviations: '\n",
    "            print stdev_A_logg5_pow\n",
    "            \n",
    "            pow_comb5_fits_dict[filter_str[i-2]] = pow_fit_A_logg5\n",
    "            pow_comb5_stdev_dict[filter_str[i-2]] = stdev_A_logg5_pow\n",
    "\n",
    "            print 'Logistic fit coefficients: '\n",
    "            print logis_fit_A_logg5\n",
    "            print 'Standard deviations: '\n",
    "            print stdev_A_logg5_logis\n",
    "            \n",
    "            logis_comb5_fits_dict[filter_str[i-2]] = logis_fit_A_logg5\n",
    "            logis_comb5_stdev_dict[filter_str[i-2]] = stdev_A_logg5_logis\n",
    "            \n",
    "            print 'Teff log-normal fit coefficients: '\n",
    "            print plog_fit_A_logg5\n",
    "            print 'Standard deviations: '\n",
    "            print stdev_A_logg5_plog\n",
    "            \n",
    "            plog_comb5_fits_dict[filter_str[i-2]] = plog_fit_A_logg5\n",
    "            plog_comb5_stdev_dict[filter_str[i-2]] = stdev_A_logg5_plog\n",
    "            \n",
    "            print 2*'\\n'\n",
    "            \n",
    "        print 'Number of fit operations = ', len(exp_fit_A_logg5_list)\n",
    "        print 'List object type: ', type(exp_fit_A_logg5_list)\n",
    "        # combine lists to store for log(g) != 5.0 function runs\n",
    "        combined_list = [exp_fit_A_logg5_list,stdev_A_logg5_ef_list,pow_fit_A_logg5_list,stdev_A_logg5_pow_list,\\\n",
    "                         logis_fit_A_logg5_list,stdev_A_logg5_logis_list,plog_fit_A_logg5_list,stdev_A_logg5_plog_list]\n",
    "        \n",
    "        comb_dict_list = [exp_comb5_fits_dict,exp_comb5_stdev_dict,pow_comb5_fits_dict,pow_comb5_stdev_dict,\\\n",
    "                          logis_comb5_fits_dict,logis_comb5_stdev_dict,plog_comb5_fits_dict,plog_comb5_stdev_dict]\n",
    "        #print combined_list\n",
    "    print '\\n         FITTING OPERATION COMPLETE \\n'\n",
    "    return combined_list,comb_dict_list\n",
    "\n",
    "\n",
    "# plot & write results\n",
    "def filter_curve_plot_write(A_X_zs_gfix,A_X_z2_gfix,A_X_z1_gfix,A_X_zh_gfix,combined_list,key,metal,extras,filter_str,var_names_comb,sig_val,folder,graph_fold,casa_opt,multiplot_file,plot_diff='n',coef_cut='',write_stuff='n',save_stuff='y',zoom_min=None,zoom_max=None):\n",
    "    if (metal == 'solar'):\n",
    "        A_X_chosen = A_X_zs_gfix[key]\n",
    "        casa_chosen = casa_arr_zs\n",
    "    elif (metal == 'sol_100'):\n",
    "        A_X_chosen = A_X_z2_gfix[key]\n",
    "        casa_chosen = casa_arr_z2\n",
    "    elif (metal == 'sol_10'):\n",
    "        A_X_chosen = A_X_z1_gfix[key]\n",
    "        casa_chosen = casa_arr_z1\n",
    "    elif (metal == 'solx3'):\n",
    "        A_X_chosen = A_X_zh_gfix[key]\n",
    "        casa_chosen = casa_arr_zh\n",
    "    else:\n",
    "        print 'Error! Incorrect metallicity input'\n",
    "        A_X_chosen = []\n",
    "    \n",
    "    if (zoom_min is not None and zoom_max is not None):\n",
    "        extras += ('_zoom_' + str(int(zoom_min)) + 'K_' + str(int(zoom_max)) + 'K')\n",
    "    \n",
    "    # Hubble data: easier to use subplots -> add option\n",
    "    if (multiplot_file == 'y'):\n",
    "        plot_dir_str_i = None\n",
    "        data_dir_str_i = None\n",
    "        if (len(A_X_chosen[0,:]) > 11):\n",
    "            fig, axs = plt.subplots(nrows=4,ncols=4,figsize=(16, 16))\n",
    "            Nrows = 4\n",
    "            Ncols = 4\n",
    "        else:\n",
    "            fig, axs = plt.subplots(nrows=3,ncols=3,figsize=(16, 16))\n",
    "            Nrows = 3\n",
    "            Ncols = 3\n",
    "            \n",
    "        axs = axs.ravel()\n",
    "        # Write out to new file: first 'with' statement empties the file to be written into later\n",
    "        data_dir_str_i = folder + '/Teff_AHub_gaia_gen_fit_logg=' + key + '_' + metal + '_' + extras + '_numbers.txt'\n",
    "        if (write_stuff == 'y' and key == '5.0' and metal == 'solar'):\n",
    "            with open (data_dir_str_i,'w') as f:\n",
    "                f.close()\n",
    "        # Iteration for changes BETWEEN filters !!!\n",
    "        for i in range(2,len(A_X_chosen[0,:])):\n",
    "            # curve-fitting commands - for log(g) = 5.0 ONLY - apply results to other log(g) values\n",
    "            # use lists filled in before (for log(g) = 5.0) to provide fit-curve data\n",
    "            exp_fit_A_logg5 = (combined_list[0])[i-2]\n",
    "            stdev_A_logg5_ef = (combined_list[1])[i-2]\n",
    "            pow_fit_A_logg5 = (combined_list[2])[i-2]\n",
    "            stdev_A_logg5_pow = (combined_list[3])[i-2]\n",
    "            logis_fit_A_logg5 = (combined_list[4])[i-2]\n",
    "            stdev_A_logg5_logis = (combined_list[5])[i-2]\n",
    "            plog_fit_A_logg5 = (combined_list[6])[i-2]\n",
    "            stdev_A_logg5_plog = (combined_list[7])[i-2]\n",
    "            \n",
    "            # check that fitting numbers are retained\n",
    "            if (i == 2 and key != '5.0'):\n",
    "                print 'Exponential fit coefficients (should be reused): '\n",
    "                print exp_fit_A_logg5\n",
    "                print 'Standard deviations (should be reused): '\n",
    "                print stdev_A_logg5_ef\n",
    "\n",
    "                print 'Teff^(n) fit coefficients (should be reused): '\n",
    "                print pow_fit_A_logg5\n",
    "                print 'Standard deviations (should be reused): '\n",
    "                print stdev_A_logg5_pow\n",
    "\n",
    "                print 'Logistic fit coefficients: '\n",
    "                print logis_fit_A_logg5\n",
    "                print 'Standard deviations: '\n",
    "                print stdev_A_logg5_logis\n",
    "                \n",
    "                print 'Teff log-normal fit coefficients: '\n",
    "                print plog_fit_A_logg5\n",
    "                print 'Standard deviations: '\n",
    "                print stdev_A_logg5_plog\n",
    "                \n",
    "                print 2*'\\n'\n",
    "            \n",
    "            \n",
    "            if (write_stuff == 'y' and key == '5.0' and metal == 'solar'):\n",
    "                avg_dict = {}\n",
    "                with open (data_dir_str_i,'a') as f:\n",
    "                    print '\\n    Writing log(g)=' + key + ', Z = ' + metal + ' model for ' + filter_str[i-2] + ' filter'\n",
    "                    general_fit_number_gen_write(f,fit_types[0],exp_fit_A_logg5, stdev_A_logg5_ef,filter_str[i-2],float(key),avg_dict)\n",
    "                    general_fit_number_gen_write(f,fit_types[1],pow_fit_A_logg5, stdev_A_logg5_pow,filter_str[i-2],float(key),avg_dict)\n",
    "                    #general_fit_number_gen_write(f,fit_types[2],logis_fit_A_logg5, stdev_A_logg5_logis,filter_str[i-2],float(key),avg_dict)\n",
    "                    #general_fit_number_gen_write(f,fit_types[3],plog_fit_A_logg5, stdev_A_logg5_plog,filter_str[i-2],float(key),avg_dict)\n",
    "\n",
    "                    # write results of comparison of averages\n",
    "                    sorted_avg = sorted(avg_dict.items(), key=operator.itemgetter(1))\n",
    "                    f.write('RANKED MEAN FRACTIONAL ERRORS (best to worst) :   ' + '\\n')\n",
    "                    for j in sorted_avg:\n",
    "                        f.write(\"{: <40}\".format(str(j[0])) + 2*'\\t' + str(j[1]) + '\\n')\n",
    "                    f.close()\n",
    "                    #_0.02\n",
    "                \n",
    "            axs[i-2].set_xlabel(var_names_comb[0])\n",
    "            axs[i-2].set_ylabel(var_names_comb[i])\n",
    "            # - 0.01 (data - 0.01) *max(A_X_chosen[:,i])*max(data)\n",
    "            # + 0.01 (data + 0.01) *max(A_X_chosen[:,i])*max(data)\n",
    "            if (plot_diff == 'y'):\n",
    "                axs[i-2].axhline(y=0,color='k',label='Data')\n",
    "                axs[i-2].axhline(y=-sig_val,color='k',linestyle='--',label='Data lower accuracy limit (data - '+str(sig_val)+')')\n",
    "                axs[i-2].axhline(y=sig_val,color='k',linestyle='--',label='Data upper accuracy limit (data + '+str(sig_val)+')')\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - 0.02),'k',linestyle='-.',label='Data lower accuracy limit (data - 0.02)')\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] + 0.02),'k',linestyle='-.',label='Data upper accuracy limit (data + 0.02)')\n",
    "                axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - exp_func(A_X_chosen[:,0],*exp_fit_A_logg5)),'m',marker='x',label=fit_types[0])\n",
    "                axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - single_poly(A_X_chosen[:,0],*pow_fit_A_logg5)),'g',marker='x',label=fit_types[1])\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - R1_logistic_func(A_X_chosen[:,0],*logis_fit_A_logg5)),'r',marker='x',label=fit_types[2])\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - R1_log_normal_func(A_X_chosen[:,0],*plog_fit_A_logg5)),'b',marker='x',label=fit_types[3])\n",
    "            else:\n",
    "                axs[i-2].plot(A_X_chosen[:,0],A_X_chosen[:,i],'k',marker='x',linestyle='',label='Data')\n",
    "                axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - sig_val),'k',linestyle='--',label='Data lower accuracy limit (data - '+str(sig_val)+')')\n",
    "                axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] + sig_val),'k',linestyle='--',label='Data upper accuracy limit (data + '+str(sig_val)+')')\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - 0.02),'k',linestyle='-.',label='Data lower accuracy limit (data - 0.02)')\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] + 0.02),'k',linestyle='-.',label='Data upper accuracy limit (data + 0.02)')\n",
    "                axs[i-2].plot(A_X_chosen[:,0],exp_func(A_X_chosen[:,0],*exp_fit_A_logg5),'m',label=fit_types[0])\n",
    "                axs[i-2].plot(A_X_chosen[:,0],single_poly(A_X_chosen[:,0],*pow_fit_A_logg5),'g',label=fit_types[1])\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],R1_logistic_func(A_X_chosen[:,0],*logis_fit_A_logg5),'r',label=fit_types[2])\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],R1_log_normal_func(A_X_chosen[:,0],*plog_fit_A_logg5),'b',label=fit_types[3])\n",
    "            if (zoom_min is not None and zoom_max is not None and (max(A_X_chosen[:,0]) >= zoom_max)):\n",
    "                axs[i-2].set_xlim(zoom_min,zoom_max)\n",
    "            title_str = filter_str[i-2] + ' filter'\n",
    "            #axs[i-2].set_title(title_str, y=1.02)\n",
    "        if ( (len(A_X_chosen[0,:]) - 2) < (Nrows*Ncols) ):\n",
    "            print 'Deleting missing subplots - discrepancy between ' + str(len(A_X_chosen[0,:]) - 2) + ' and ' + str(Nrows*Ncols)\n",
    "            for d in range((len(A_X_chosen[0,:]) - 2),(Nrows*Ncols)):\n",
    "                fig.delaxes(axs[d])\n",
    "        \n",
    "        if (plot_diff == 'y'):\n",
    "            plot_dir_str_i = folder + '/' + graph_fold + '/diff_AHub_logg=' + key + '_' + metal + '_' + extras + '_Teff_fit_plot'+coef_cut+'.pdf'\n",
    "        else:\n",
    "            plot_dir_str_i = folder + '/' + graph_fold + '/AHub_logg=' + key + '_' + metal + '_' + extras + '_Teff_fit_plot'+coef_cut+'.pdf'\n",
    "\n",
    "        sup_title_str = 'Extinction plots for log(g) = ' + key + ', Z = Z' + metal\n",
    "        #fig.suptitle(sup_title_str,size=16)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.92) # 0.88\n",
    "        plt.show()\n",
    "        if(save_stuff == 'y'):\n",
    "            fig.savefig(plot_dir_str_i, bbox_inches='tight')\n",
    "\n",
    "    else:\n",
    "        # Iteration for changes BETWEEN filters !!!\n",
    "        # i.e., should produce 3 versions of each output each time the function is called\n",
    "        for i in range(2,len(A_X_chosen[0,:])):\n",
    "            # empty directory string - avoid potential concatonation\n",
    "            plot_dir_str_i = None\n",
    "            data_dir_str_i = None\n",
    "            # curve-fitting commands\n",
    "            exp_fit_A_logg5 = (combined_list[0])[i-2]\n",
    "            stdev_A_logg5_ef = (combined_list[1])[i-2]\n",
    "            pow_fit_A_logg5 = (combined_list[2])[i-2]\n",
    "            stdev_A_logg5_pow = (combined_list[3])[i-2]\n",
    "            logis_fit_A_logg5 = (combined_list[4])[i-2]\n",
    "            stdev_A_logg5_logis = (combined_list[5])[i-2]\n",
    "\n",
    "            # check that fitting numbers are retained\n",
    "            if (i == 2):\n",
    "                print 'Exponential fit coefficients (should be reused): '\n",
    "                print exp_fit_A_logg5\n",
    "                print 'Standard deviations (should be reused): '\n",
    "                print stdev_A_logg5_ef\n",
    "\n",
    "                print 'Teff^(n) fit coefficients (should be reused): '\n",
    "                print pow_fit_A_logg5\n",
    "                print 'Standard deviations (should be reused): '\n",
    "                print stdev_A_logg5_pow\n",
    "\n",
    "                #print 'Logistic fit coefficients: '\n",
    "                #print logis_fit_A_logg5\n",
    "                #print 'Standard deviations: '\n",
    "                #print stdev_A_logg5_logis\n",
    "                \n",
    "                print 2*'\\n'\n",
    "\n",
    "            # Construct directories, files to save plots,data - i.e. construct strings\n",
    "            # String format should be: 'gaia_spectra/gaia_graphs/AGrp_logg=5.0_Teff_fit_plot.pdf' (example case)\n",
    "            if (casa_opt == 'y' and i == 2):\n",
    "                folder += '_casa'\n",
    "                graph_fold += '_casa'\n",
    "\n",
    "            plot_dir_str_i = folder + '/' + graph_fold + '/A' + filter_str[i-2] + '_logg=' + key + '_' + metal + '_' + extras + '_Teff_fit_plot'\n",
    "            data_dir_str_i = folder + '/Teff_A' + filter_str[i-2] + '_gen_fit_logg=' + key + '_' + metal + '_' + extras + '_numbers'\n",
    "            # separate Casagrande data\n",
    "            if (casa_opt == 'y'): # and i == 2\n",
    "                plot_dir_str_i += '_casa'\n",
    "                data_dir_str_i += '_casa'\n",
    "            plot_dir_str_i += '.pdf'\n",
    "            data_dir_str_i += '.txt'\n",
    "            \n",
    "            # plot commands\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.set_xlabel(var_names[0])\n",
    "            ax.set_ylabel(var_names[i])\n",
    "            if (casa_opt == 'y'):\n",
    "                ax.plot(A_X_chosen[:,0],A_X_chosen[:,i],'k',marker='x',linestyle='-',label='Data')\n",
    "                ax.plot(A_X_chosen[:,0],(A_X_chosen[:,i] - 0.01),'k',linestyle='-.',label='Data lower accuracy limit (data - 0.01)')\n",
    "                ax.plot(A_X_chosen[:,0],(A_X_chosen[:,i] + 0.01),'k',linestyle='--',label='Data upper accuracy limit (data + 0.01)')\n",
    "                ax.plot(casa_chosen[:,0],casa_chosen[:,i],'b',marker='x',linestyle='-',label='Casagrande data')\n",
    "                if (zoom_min is not None and zoom_max is not None):\n",
    "                    ax.set_xlim(zoom_min,zoom_max)\n",
    "            else:\n",
    "                # - 0.01 (data - 0.01) *max(A_X_chosen[:,i])*max(data)\n",
    "                # + 0.01 (data + 0.01) *max(A_X_chosen[:,i])*max(data)\n",
    "                ax.plot(A_X_chosen[:,0],A_X_chosen[:,i],'k',marker='x',linestyle='',label='Data')\n",
    "                ax.plot(A_X_chosen[:,0],(A_X_chosen[:,i] - 0.01),'k',linestyle='-.',label='Data lower accuracy limit (data - 0.01)')\n",
    "                ax.plot(A_X_chosen[:,0],(A_X_chosen[:,i] + 0.01),'k',linestyle='--',label='Data upper accuracy limit (data + 0.01)')\n",
    "                ax.plot(A_X_chosen[:,0],exp_func(A_X_chosen[:,0],*exp_fit_A_logg5),'m',label=fit_types[0])\n",
    "                ax.plot(A_X_chosen[:,0],single_poly(A_X_chosen[:,0],*pow_fit_A_logg5),'g',label=fit_types[1])\n",
    "                #ax.plot(A_X_chosen[:,0],R1_logistic_func(A_X_chosen[:,0],*logis_fit_A_logg5),'r',label=fit_types[2])\n",
    "                #ax.plot(A_X_chosen[:,0],R1_log_normal_func(A_X_chosen[:,0],*plog_fit_A_logg5),'b',label=fit_types[3])\n",
    "                if (zoom_min is not None and zoom_max is not None):\n",
    "                    ax.set_xlim(zoom_min,zoom_max)\n",
    "            \n",
    "            plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "            plt.show()\n",
    "            if (save_stuff == 'y'):\n",
    "                fig.savefig(plot_dir_str_i, bbox_inches='tight')\n",
    "\n",
    "            # data file write commands\n",
    "            \n",
    "            avg_dict = {}\n",
    "            if (write_stuff == 'y'):\n",
    "                with open (data_dir_str_i,'w') as f:\n",
    "                    print '\\n    Writing log(g)=' + key + ', Z = ' + metal + ' model'\n",
    "                    general_fit_number_gen_write(f,fit_types[0],exp_fit_A_logg5, stdev_A_logg5_ef,filter_str[i-2],float(key),avg_dict)\n",
    "                    general_fit_number_gen_write(f,fit_types[1],pow_fit_A_logg5, stdev_A_logg5_pow,filter_str[i-2],float(key),avg_dict)\n",
    "                    #general_fit_number_gen_write(f,fit_types[2],logis_fit_A_logg5, stdev_A_logg5_logis,filter_str[i-2],float(key),avg_dict)\n",
    "                    #general_fit_number_gen_write(f,fit_types[3],plog_fit_A_logg5, stdev_A_logg5_plog,filter_str[i-2],float(key),avg_dict)\n",
    "\n",
    "                    # write results of comparison of averages\n",
    "                    sorted_avg = sorted(avg_dict.items(), key=operator.itemgetter(1))\n",
    "                    f.write('RANKED MEAN FRACTIONAL ERRORS (best to worst) :   \\n')\n",
    "                    for j in sorted_avg:\n",
    "                        f.write(\"{: <40}\".format(str(j[0])) + 2*'\\t' + str(j[1]) + '\\n')\n",
    "                    f.close()\n",
    "\n",
    "                #with open (folder + '/coeffs_summary_cas.txt','a') as sf:\n",
    "                    #sf.write('Fit coefficients summary')\n",
    "                    #sf.write('log(g) = ' + key + ', Z = ' + metal + ', ' + filter_str[i-2] + ' filter ' + 3*'\\t' + str(pow_fit_A_logg5) + '\\n')\n",
    "                #sf.close()\n",
    "            print 'Writing complete for ' + filter_str[i-2] + ' filter'\n",
    "    print '\\n    Writing complete for log(g) = ' + key + ', Z = ' + metal + ' configuration, END OF FUNCTION WRITING!!!'\n",
    "\n",
    "def combine_filter_systems_dict(Afirst,Asecond):\n",
    "    comb_dict = {}\n",
    "    for key in sorted(Afirst.iterkeys()):\n",
    "        #print key\n",
    "        first_arr = Afirst[key]\n",
    "        second_arr = Asecond[key]\n",
    "        nfilters_second = (len(second_arr[0,:]) - 2)\n",
    "\n",
    "        comb_arr = np.zeros((len(first_arr[:,0]),(len(first_arr[0,:]) + nfilters_second)))\n",
    "        comb_arr[:,:-nfilters_second] = np.copy(first_arr)\n",
    "        comb_arr[:,-nfilters_second:] = np.copy(second_arr[:,2:len(second_arr[0,:])])\n",
    "        #comb_arr_zs = np.append(first_arr_zs,second_arr_zs[:,2:5])\n",
    "        comb_dict[key] = comb_arr\n",
    "        #print nfilters_second,len(comb_arr[0,:])\n",
    "    return comb_dict\n",
    "\n",
    "# extract coefficients into a summary file\n",
    "def make_coeffs_summary(directory,infile,outfile,filter_names,logg_val,metal,writing_type):\n",
    "    locin = directory + infile\n",
    "    locout = directory + outfile\n",
    "\n",
    "    with open(locin,'r') as inputf, open(locout,writing_type) as outputf:\n",
    "        n = 0\n",
    "        copy_bool = False\n",
    "        #outputf.write('Coefficients for Teff power law: \\n\\n')\n",
    "        #if (n <= (len(filter_names)-1)):\n",
    "        #copy_bool = False\n",
    "        for line in inputf:\n",
    "            #if ('Fitting results for' in line.strip()): == '    Covariance matrix:'\n",
    "                #outputf.write(line)\n",
    "            if (line.strip() == 'Function type:  Power law of Teff, fitted'):\n",
    "                copy_bool = True\n",
    "                n += 1\n",
    "            elif ('Covariance' in line.strip()):\n",
    "                copy_bool = False\n",
    "            elif copy_bool:\n",
    "                if ('Fit coefficients (in order of functions arguments)' in line.strip()):\n",
    "                    continue\n",
    "                else:\n",
    "                    print n\n",
    "                    outputf.write(filter_names[n-1] + ' filter, with  log(g) = ' + logg_val + ' and Z = Z' + metal + ': \\t\\t' + line)\n",
    "                    \n",
    "\n",
    "        outputf.write('#\\n#\\n')\n",
    "        inputf.close()\n",
    "        outputf.close()\n",
    "\n",
    "# Cutoff - tailflick evasion for fixed-log(g) dictionaries\n",
    "def Teff_cutoff_fix_logg_dict(old_dict,criterion):\n",
    "    new_dict = {}\n",
    "    x = 0\n",
    "    print 'Cutoff - tailflick evasion for fixed-log(g) dictionaries'\n",
    "    for key in sorted(old_dict.iterkeys()):\n",
    "        temp_arr_list = []\n",
    "        #print new_dict[key].shape\n",
    "        for i in range(len(old_dict[key][:,0])):\n",
    "            if (old_dict[key][i,0] >= criterion):\n",
    "                temp_arr_list.append(old_dict[key][i,:])\n",
    "                #print 'Teff value too low: ',new_dict[key][i,0]\n",
    "            elif(x == 0 and old_dict[key][i,0] < criterion):\n",
    "                print old_dict[key][i,0]\n",
    "        new_dict[key] = np.array(temp_arr_list)\n",
    "        x += 1\n",
    "    print x\n",
    "    return new_dict\n",
    "\n",
    "# High-Teff cutoff for log(g) effect modelling for fixed-Teff dictionaries\n",
    "def Teff_cutoff_fix_Teff_dict(old_dict,lower_lim,upper_lim=50000.0):\n",
    "    new_dict = {}\n",
    "    #print 'High-Teff cutoff for log(g) effect modelling for fixed-Teff dictionaries'\n",
    "    \n",
    "    for key in sorted(old_dict.iterkeys()):\n",
    "        float_key_val = float(key)\n",
    "        #print float_key_val\n",
    "        if (lower_lim <= float_key_val <= upper_lim):\n",
    "            new_dict[key] = old_dict[key]\n",
    "            #print float_key_val\n",
    "            \n",
    "    print 'Dictionary size (number of Teff values, full dictionary then cutoff-limited): '\n",
    "    print len(old_dict),len(new_dict)\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "# function to generate difference dictionaries, with arrays of varying log(g) for fitting (Teff-value keys)\n",
    "def diff_from_ref_Teff_key(input_dict,Teff_max_lim=None):\n",
    "    out_dict = {}\n",
    "    for key in sorted(input_dict.iterkeys()):\n",
    "        if (Teff_max_lim is not None and float(key) <= Teff_max_lim):\n",
    "            holder_arr = (input_dict[key])\n",
    "            i_list = []\n",
    "            for i in range(len(holder_arr[:,0])): # iterate over rows\n",
    "                j_list = []\n",
    "                for j in range(len(holder_arr[0,:])): # iterate over columns in row\n",
    "                    if (j==0 or j==1):\n",
    "                        j_val = holder_arr[i,j]\n",
    "                    else:\n",
    "                        j_val = (holder_arr[i,j] - holder_arr[-1,j])\n",
    "                    j_list.append(j_val)\n",
    "                i_list.append(j_list)\n",
    "            out_dict[key] = np.array(i_list)\n",
    "            #print 'Teff cut check for key = '+key,out_dict[key].shape\n",
    "            # current layout: only difference values for Teff < Teff_max_lim\n",
    "    return out_dict\n",
    "\n",
    "# function to generate difference dictionaries, with arrays of varying Teff for fitting (log(g) values as keys, same as final plot format)\n",
    "def diff_from_ref_logg_key(input_dict,R1_sim_dict,Teff_max_lim=None,ref_sim_yn='n'):\n",
    "    out_dict = {}\n",
    "    for key in sorted(input_dict.iterkeys()):\n",
    "        holder_arr = input_dict[key]\n",
    "        # ref_sim_yn indicates whether the reference dictionary to be used is a dictionary of data\n",
    "        # generated using the R1 coefficients or the dictionary's own data using log(g)=5.0\n",
    "        if (ref_sim_yn == 'n'):\n",
    "            ref_arr = input_dict['5.0']\n",
    "        else:\n",
    "            ref_arr = R1_sim_dict[key]\n",
    "        i_list = []\n",
    "        for i in range(len(holder_arr[:,0])): # iterate over rows\n",
    "            if (Teff_max_lim is not None and holder_arr[i,0] <= Teff_max_lim):\n",
    "                j_list = []\n",
    "                for j in range(len(holder_arr[0,:])): # iterate over columns in row\n",
    "                    if (j==0 or j==1):\n",
    "                        j_val = holder_arr[i,j]\n",
    "                    else:\n",
    "                        j_val = (holder_arr[i,j] - ref_arr[i,j])\n",
    "                    j_list.append(j_val)\n",
    "                i_list.append(j_list)\n",
    "        if (i_list != []):\n",
    "            out_dict[key] = np.array(i_list)\n",
    "            #print 'Teff cut check for key = '+key,out_dict[key].shape\n",
    "    return out_dict\n",
    "\n",
    "# for Teff-only functions, create dictionary to store data from results of round 1 coefficient fitting\n",
    "def make_sim_Teff_R1_array(input_dict,best_fits_filterwise):\n",
    "    out_dict = {}\n",
    "    for key in sorted(input_dict.iterkeys()):\n",
    "        holder_arr = np.copy(input_dict[key])\n",
    "        i_list = []\n",
    "        for i in range(len(holder_arr[:,0])): # iterate over rows\n",
    "            j_list = []\n",
    "            for j in range(len(holder_arr[0,:])): # iterate over columns in row\n",
    "                if (j==0 or j==1):\n",
    "                    j_val = holder_arr[i,j]\n",
    "                else:\n",
    "                    if (best_fits_filterwise[j-2] == 'exp'):\n",
    "                        j_val = exp_func(holder_arr[i,0], *exp_Teff_coef_4500K_logg_5[j-2])\n",
    "                    elif (best_fits_filterwise[j-2] == 'plpe'):\n",
    "                        j_val = full_pow_plus_exp_func(holder_arr[i,0], *plpe_Teff_coef_4500K_logg_5[j-2])\n",
    "                    else: # treat 'pow' as the standard\n",
    "                        j_val = single_poly(holder_arr[i,0], *pow_Teff_coef_4500K_logg_5[j-2])\n",
    "                j_list.append(j_val)\n",
    "            i_list.append(j_list)\n",
    "        out_dict[key] = np.array(i_list)\n",
    "    return out_dict\n",
    "def folder_read_in(dir_str,dir_list,metal_str_convert,Av_non0_val=1.0):\n",
    "    count_obj = 0\n",
    "    folder_Av0_dict = {}\n",
    "    folder_Av1_dict = {}\n",
    "    sys_key_str = ''\n",
    "    for atmos_file in dir_list:\n",
    "        # avoid the folder with 'just_' in its name\n",
    "        if ('OUTPUT_' in atmos_file and '_3dp' not in atmos_file):\n",
    "            count_obj += 1\n",
    "            # Rv value\n",
    "            find_Rv_val = re.search('_Rv(.+?)_Av',atmos_file)\n",
    "            if find_Rv_val:\n",
    "                found_Rv = float(find_Rv_val.group(1))\n",
    "            else:\n",
    "                found_Rv = 3.1\n",
    "            # Av value\n",
    "            find_Av_val = re.search('_Av(.+?)_z',atmos_file)\n",
    "            if find_Av_val:\n",
    "                found_Av = float(find_Av_val.group(1))\n",
    "            # metallicity\n",
    "            find_metal = re.search('_z(.*)',atmos_file)\n",
    "            if find_metal:\n",
    "                temp_key = str(find_metal.group(1))\n",
    "                found_metal = metal_str_convert[temp_key]\n",
    "            # Photometric system\n",
    "            # ACS\n",
    "            if 'ACS_OUTPUT' in atmos_file:\n",
    "                sys_key_str = 'acs'\n",
    "            # WFC3\n",
    "            elif 'H_OUTPUT' in atmos_file:\n",
    "                sys_key_str = 'wfc3'\n",
    "            # Gaia (all other files)\n",
    "            else:\n",
    "                sys_key_str = 'gaia'\n",
    "\n",
    "            with open(dir_str+atmos_file,'r') as data_file:\n",
    "                temp_store = data_read_gaia(data_file)\n",
    "                data_file.close()\n",
    "            #FORMAT: test_dict_4key = '6.0,1.0 FeH-2.0 - gaia'\n",
    "            print count_obj,'Av = '+str(found_Av),'keys: ',str(found_Rv),str(found_metal),sys_key_str\n",
    "            if (found_Av == 0.0):\n",
    "                folder_Av0_dict[str(found_Rv)+',FeH'+str(found_metal)+':'+sys_key_str] = temp_store\n",
    "            elif (found_Av == Av_non0_val):\n",
    "                folder_Av1_dict[str(found_Rv)+',FeH'+str(found_metal)+':'+sys_key_str] = temp_store\n",
    "            else:\n",
    "                print 'Error! Check process again'\n",
    "    print 'Av = 0 dictionary length: ', len(folder_Av0_dict),', non-zero Av dictionary length: ', len(folder_Av1_dict)\n",
    "    for key in folder_Av0_dict.keys(): \n",
    "        if not key in folder_Av1_dict:\n",
    "            print 'Key missing for non-zero Av dictionary:',key\n",
    "    for key in folder_Av1_dict.keys(): \n",
    "        if not key in folder_Av0_dict:\n",
    "            print 'Key missing for Av = 0 dictionary:',key\n",
    "    print '\\n***********************'\n",
    "    return folder_Av0_dict,folder_Av1_dict\n",
    "\n",
    "def extract_params_from_4key(test_dict):\n",
    "    params_dict = {}\n",
    "    for test_dict_4key in test_dict:\n",
    "        print test_dict_4key\n",
    "        params_4key = []\n",
    "        print 'extracting Rv, Av, [Fe/H] and system from key'\n",
    "        find_Rv = re.search('(.*),',test_dict_4key)\n",
    "        if (find_Rv):\n",
    "            found_Rv = float(find_Rv.group(1))\n",
    "            params_4key.append(found_Rv)\n",
    "        find_Av = re.search(',(.+?) FeH',test_dict_4key)\n",
    "        if (find_Av):\n",
    "            found_Av = float(find_Av.group(1))\n",
    "            params_4key.append(found_Av)\n",
    "        find_metal = re.search('FeH(.+?) -',test_dict_4key)\n",
    "        if (find_metal):\n",
    "            found_metal = float(find_metal.group(1))\n",
    "            params_4key.append(found_metal)\n",
    "        find_sys = re.search(' - (.*)',test_dict_4key)\n",
    "        if (find_sys):\n",
    "            found_sys = str(find_sys.group(1))\n",
    "            params_4key.append(found_sys)\n",
    "        print 'Parameters found in key (should be 3):',params_4key\n",
    "        params_dict[test_dict_4key] = params_4key\n",
    "    return params_dict\n",
    "\n",
    "print 'functions, modules done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6 3.1 5.6\n",
      "0.384615384615 0.322580645161 0.178571428571\n"
     ]
    }
   ],
   "source": [
    "# list of line-of-sight Rv values for the sources listed in Cardelli et al. (1989)\n",
    "Rv_list_CCM89 = [2.85,3.42,5.60,5.50,5.23,5.10,4.11,5.30,3.12,3.52,3.39,3.92,4.98,4.04,4.13,4.20,4.34,3.09,3.15,\\\n",
    "                 5.30,3.48,3.05,2.60,3.12,3.33,2.75,4.17,2.84,3.71,3.33]\n",
    "\n",
    "print min(Rv_list_CCM89),3.1,max(Rv_list_CCM89)\n",
    "print 1.0/min(Rv_list_CCM89),1.0/3.1,1.0/max(Rv_list_CCM89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaia data read \n",
      "\n",
      "\n",
      "Total dataset:  (476L, 9L)\n",
      "1 Av = 0.0 keys:  2.0 0.5 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "2 Av = 0.0 keys:  2.0 -1.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "3 Av = 0.0 keys:  2.0 -2.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "4 Av = 0.0 keys:  2.0 0.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "5 Av = 1.0 keys:  2.0 0.5 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "6 Av = 1.0 keys:  2.0 -1.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "7 Av = 1.0 keys:  2.0 -2.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "8 Av = 1.0 keys:  2.0 0.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "9 Av = 0.0 keys:  6.0 0.5 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "10 Av = 0.0 keys:  6.0 -1.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "11 Av = 0.0 keys:  6.0 -2.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "12 Av = 0.0 keys:  6.0 0.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "13 Av = 1.0 keys:  6.0 0.5 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "14 Av = 1.0 keys:  6.0 -1.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "15 Av = 1.0 keys:  6.0 -2.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "16 Av = 1.0 keys:  6.0 0.0 acs\n",
      "Total dataset:  (476L, 15L)\n",
      "17 Av = 0.0 keys:  2.0 0.5 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "18 Av = 0.0 keys:  2.0 -1.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "19 Av = 0.0 keys:  2.0 -2.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "20 Av = 0.0 keys:  2.0 0.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "21 Av = 1.0 keys:  2.0 0.5 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "22 Av = 1.0 keys:  2.0 -1.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "23 Av = 1.0 keys:  2.0 -2.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "24 Av = 1.0 keys:  2.0 0.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "25 Av = 0.0 keys:  6.0 0.5 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "26 Av = 0.0 keys:  6.0 -1.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "27 Av = 0.0 keys:  6.0 -2.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "28 Av = 0.0 keys:  6.0 0.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "29 Av = 1.0 keys:  6.0 0.5 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "30 Av = 1.0 keys:  6.0 -1.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "31 Av = 1.0 keys:  6.0 -2.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "32 Av = 1.0 keys:  6.0 0.0 wfc3\n",
      "Total dataset:  (476L, 5L)\n",
      "33 Av = 0.0 keys:  2.0 0.5 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "34 Av = 0.0 keys:  2.0 -1.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "35 Av = 0.0 keys:  2.0 -2.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "36 Av = 0.0 keys:  2.0 0.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "37 Av = 1.0 keys:  2.0 0.5 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "38 Av = 1.0 keys:  2.0 -1.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "39 Av = 1.0 keys:  2.0 -2.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "40 Av = 1.0 keys:  2.0 0.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "41 Av = 0.0 keys:  6.0 0.5 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "42 Av = 0.0 keys:  6.0 -1.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "43 Av = 0.0 keys:  6.0 -2.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "44 Av = 0.0 keys:  6.0 0.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "45 Av = 1.0 keys:  6.0 0.5 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "46 Av = 1.0 keys:  6.0 -1.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "47 Av = 1.0 keys:  6.0 -2.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "48 Av = 1.0 keys:  6.0 0.0 gaia\n",
      "Av = 0 dictionary length:  24 , non-zero Av dictionary length:  24\n",
      "\n",
      "***********************\n",
      "Total dataset:  (476L, 5L)\n",
      "1 Av = 0.0 keys:  3.1 0.5 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "2 Av = 0.0 keys:  3.1 -1.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "3 Av = 0.0 keys:  3.1 -2.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "4 Av = 0.0 keys:  3.1 0.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "5 Av = 1.0 keys:  3.1 0.5 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "6 Av = 1.0 keys:  3.1 -1.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "7 Av = 1.0 keys:  3.1 -2.0 gaia\n",
      "Total dataset:  (476L, 5L)\n",
      "8 Av = 1.0 keys:  3.1 0.0 gaia\n",
      "Av = 0 dictionary length:  4 , non-zero Av dictionary length:  4\n",
      "\n",
      "***********************\n",
      "Total dataset:  (476L, 15L)\n",
      "1 Av = 0.0 keys:  3.1 0.5 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "2 Av = 0.0 keys:  3.1 -1.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "3 Av = 0.0 keys:  3.1 -2.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "4 Av = 0.0 keys:  3.1 0.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "5 Av = 1.0 keys:  3.1 0.5 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "6 Av = 1.0 keys:  3.1 -1.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "7 Av = 1.0 keys:  3.1 -2.0 wfc3\n",
      "Total dataset:  (476L, 15L)\n",
      "8 Av = 1.0 keys:  3.1 0.0 wfc3\n",
      "Av = 0 dictionary length:  4 , non-zero Av dictionary length:  4\n",
      "\n",
      "***********************\n",
      "Total dataset:  (476L, 9L)\n",
      "1 Av = 0.0 keys:  3.1 0.5 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "2 Av = 0.0 keys:  3.1 -1.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "3 Av = 0.0 keys:  3.1 -2.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "4 Av = 0.0 keys:  3.1 0.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "5 Av = 1.0 keys:  3.1 0.5 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "6 Av = 1.0 keys:  3.1 -1.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "7 Av = 1.0 keys:  3.1 -2.0 acs\n",
      "Total dataset:  (476L, 9L)\n",
      "8 Av = 1.0 keys:  3.1 0.0 acs\n",
      "Av = 0 dictionary length:  4 , non-zero Av dictionary length:  4\n",
      "\n",
      "***********************\n",
      "36\n",
      "2.0,FeH-1.0:acs\n",
      "2.0,FeH-1.0:gaia\n",
      "2.0,FeH-1.0:wfc3\n",
      "2.0,FeH-2.0:acs\n",
      "2.0,FeH-2.0:gaia\n",
      "2.0,FeH-2.0:wfc3\n",
      "2.0,FeH0.0:acs\n",
      "2.0,FeH0.0:gaia\n",
      "2.0,FeH0.0:wfc3\n",
      "2.0,FeH0.5:acs\n",
      "2.0,FeH0.5:gaia\n",
      "2.0,FeH0.5:wfc3\n",
      "3.1,FeH-1.0:acs\n",
      "3.1,FeH-1.0:gaia\n",
      "3.1,FeH-1.0:wfc3\n",
      "3.1,FeH-2.0:acs\n",
      "3.1,FeH-2.0:gaia\n",
      "3.1,FeH-2.0:wfc3\n",
      "3.1,FeH0.0:acs\n",
      "3.1,FeH0.0:gaia\n",
      "3.1,FeH0.0:wfc3\n",
      "3.1,FeH0.5:acs\n",
      "3.1,FeH0.5:gaia\n",
      "3.1,FeH0.5:wfc3\n",
      "6.0,FeH-1.0:acs\n",
      "6.0,FeH-1.0:gaia\n",
      "6.0,FeH-1.0:wfc3\n",
      "6.0,FeH-2.0:acs\n",
      "6.0,FeH-2.0:gaia\n",
      "6.0,FeH-2.0:wfc3\n",
      "6.0,FeH0.0:acs\n",
      "6.0,FeH0.0:gaia\n",
      "6.0,FeH0.0:wfc3\n",
      "6.0,FeH0.5:acs\n",
      "6.0,FeH0.5:gaia\n",
      "6.0,FeH0.5:wfc3\n",
      "\n",
      "\n",
      "36\n",
      "2.0,FeH-1.0:acs\n",
      "2.0,FeH-1.0:gaia\n",
      "2.0,FeH-1.0:wfc3\n",
      "2.0,FeH-2.0:acs\n",
      "2.0,FeH-2.0:gaia\n",
      "2.0,FeH-2.0:wfc3\n",
      "2.0,FeH0.0:acs\n",
      "2.0,FeH0.0:gaia\n",
      "2.0,FeH0.0:wfc3\n",
      "2.0,FeH0.5:acs\n",
      "2.0,FeH0.5:gaia\n",
      "2.0,FeH0.5:wfc3\n",
      "3.1,FeH-1.0:acs\n",
      "3.1,FeH-1.0:gaia\n",
      "3.1,FeH-1.0:wfc3\n",
      "3.1,FeH-2.0:acs\n",
      "3.1,FeH-2.0:gaia\n",
      "3.1,FeH-2.0:wfc3\n",
      "3.1,FeH0.0:acs\n",
      "3.1,FeH0.0:gaia\n",
      "3.1,FeH0.0:wfc3\n",
      "3.1,FeH0.5:acs\n",
      "3.1,FeH0.5:gaia\n",
      "3.1,FeH0.5:wfc3\n",
      "6.0,FeH-1.0:acs\n",
      "6.0,FeH-1.0:gaia\n",
      "6.0,FeH-1.0:wfc3\n",
      "6.0,FeH-2.0:acs\n",
      "6.0,FeH-2.0:gaia\n",
      "6.0,FeH-2.0:wfc3\n",
      "6.0,FeH0.0:acs\n",
      "6.0,FeH0.0:gaia\n",
      "6.0,FeH0.0:wfc3\n",
      "6.0,FeH0.5:acs\n",
      "6.0,FeH0.5:gaia\n",
      "6.0,FeH0.5:wfc3\n",
      "\n",
      " done\n"
     ]
    }
   ],
   "source": [
    "# N.B.: using cgs units\n",
    "\n",
    "# change nummpy print options from default\n",
    "np.set_printoptions(precision=4)\n",
    "    \n",
    "print 'Gaia data read '\n",
    "print '\\n'\n",
    "\n",
    "dir_str = 'Rv_varied/'\n",
    "dir_list = os.listdir(dir_str)\n",
    "\n",
    "dir_str_3p1_gaia = 'gaia_spectra/'\n",
    "dir_list_3p1_gaia = os.listdir(dir_str_3p1_gaia)\n",
    "\n",
    "dir_str_3p1_wfc3 = 'HubWFC/'\n",
    "dir_list_3p1_wfc3 = os.listdir(dir_str_3p1_wfc3)\n",
    "\n",
    "dir_str_3p1_acs = 'ACS_hubble/'\n",
    "dir_list_3p1_acs = os.listdir(dir_str_3p1_acs)\n",
    "\n",
    "metal_str_convert = {\n",
    "    '10+half' : 0.5,\n",
    "    '10-1' : -1.0,\n",
    "    '10-2' : -2.0,\n",
    "    'solar' : 0.0\n",
    "}\n",
    "\n",
    "# read in first from variable-Rv folder\n",
    "all_combs_Av0_dict,all_combs_Av1_dict = folder_read_in(dir_str,dir_list,metal_str_convert)\n",
    "# next, read in from the 3 different folders containing the Rv = 3.1 data used previously \n",
    "all_combs_Rv_3p1_gaia_Av0_dict,all_combs_Rv_3p1_gaia_Av1_dict = folder_read_in(dir_str_3p1_gaia,dir_list_3p1_gaia,metal_str_convert)\n",
    "all_combs_Rv_3p1_wfc3_Av0_dict,all_combs_Rv_3p1_wfc3_Av1_dict = folder_read_in(dir_str_3p1_wfc3,dir_list_3p1_wfc3,metal_str_convert)\n",
    "all_combs_Rv_3p1_acs_Av0_dict,all_combs_Rv_3p1_acs_Av1_dict = folder_read_in(dir_str_3p1_acs,dir_list_3p1_acs,metal_str_convert)\n",
    "\n",
    "# add the results from the Rv = 3.1 data to those for other Rv values\n",
    "for folder_dict in (all_combs_Rv_3p1_gaia_Av0_dict,all_combs_Rv_3p1_wfc3_Av0_dict,all_combs_Rv_3p1_acs_Av0_dict):\n",
    "    all_combs_Av0_dict.update(folder_dict)\n",
    "\n",
    "for folder_dict in (all_combs_Rv_3p1_gaia_Av1_dict,all_combs_Rv_3p1_wfc3_Av1_dict,all_combs_Rv_3p1_acs_Av1_dict):\n",
    "    all_combs_Av1_dict.update(folder_dict)\n",
    "\n",
    "print len(all_combs_Av0_dict)\n",
    "for key in sorted(all_combs_Av0_dict.iterkeys()):\n",
    "    print key\n",
    "print '\\n'\n",
    "print len(all_combs_Av1_dict)\n",
    "for key in sorted(all_combs_Av1_dict.iterkeys()):\n",
    "    print key\n",
    "    \n",
    "#print '\\n'\n",
    "#all_param_combs = extract_params_from_4key(all_combs_dict)\n",
    "print '\\n done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Creating arrays****\n",
      "****Separating data into arrays by log(g) values****\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH-2.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH0.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH-1.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH-1.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH0.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH0.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH-2.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH-1.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH-2.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH-1.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH-2.0:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH-2.0:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH-1.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH-2.0:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH0.0:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH-1.0:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH0.5:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH0.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH-2.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH0.5:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH0.5:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH0.5:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH0.5:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH0.5:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH0.0:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH0.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH0.5:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH0.5:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH-1.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH0.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH0.5:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH-2.0:gaia <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH-2.0:wfc3 <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "6.0,FeH-1.0:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "2.0,FeH-1.0:acs <type 'str'>\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "Table column  2  values list:  [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "Final dictionary length:  11\n",
      "combined set size: 11\n",
      "Raw A(X) dictionary complete\n",
      "3.1,FeH0.0:acs <type 'str'>\n",
      "\n",
      "\n",
      "4.5 <type 'dict'> <type 'numpy.ndarray'>\n",
      "1.5 <type 'dict'> <type 'numpy.ndarray'>\n",
      "1.0 <type 'dict'> <type 'numpy.ndarray'>\n",
      "4.0 <type 'dict'> <type 'numpy.ndarray'>\n",
      "0.0 <type 'dict'> <type 'numpy.ndarray'>\n",
      "0.5 <type 'dict'> <type 'numpy.ndarray'>\n",
      "3.5 <type 'dict'> <type 'numpy.ndarray'>\n",
      "3.0 <type 'dict'> <type 'numpy.ndarray'>\n",
      "2.0 <type 'dict'> <type 'numpy.ndarray'>\n",
      "5.0 <type 'dict'> <type 'numpy.ndarray'>\n",
      "2.5 <type 'dict'> <type 'numpy.ndarray'>\n",
      "6.0,-2.0 <type 'dict'>\n",
      "3.1,-2.0 <type 'dict'>\n",
      "3.1,-1.0 <type 'dict'>\n",
      "6.0,-1.0 <type 'dict'>\n",
      "6.0,0.0 <type 'dict'>\n",
      "2.0,-1.0 <type 'dict'>\n",
      "3.1,0.5 <type 'dict'>\n",
      "6.0,0.5 <type 'dict'>\n",
      "2.0,0.0 <type 'dict'>\n",
      "2.0,-2.0 <type 'dict'>\n",
      "2.0,0.5 <type 'dict'>\n",
      "3.1,0.0 <type 'dict'>\n",
      "12\n",
      "ACS filter labels length:  7\n",
      "Variable data arrays organized\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Rv value\n",
    "find_Rv_val = re.search('_Rv(.+?)_Av',atmos_file)\n",
    "if find_Rv_val:\n",
    "    found_Rv = float(find_Rv_val.group(1))\n",
    "# Av value\n",
    "find_Av_val = re.search('_Av(.+?)_z',atmos_file)\n",
    "if find_Av_val:\n",
    "    found_Av = float(find_Av_val.group(1))\n",
    "# metallicity\n",
    "find_metal = re.search('_z(.*)',atmos_file)\n",
    "if find_metal:\n",
    "    temp_key = str(find_metal.group(1))\n",
    "    found_metal = metal_str_convert[temp_key]\n",
    "# Photometric system\n",
    "# ACS\n",
    "if 'ACS_OUTPUT' in atmos_file:\n",
    "    sys_key_str = 'acs'\n",
    "# WFC3\n",
    "elif 'H_OUTPUT' in atmos_file:\n",
    "    sys_key_str = 'wfc3'\n",
    "# Gaia (all other files)\n",
    "else:\n",
    "    sys_key_str = 'gaia'\n",
    "\n",
    "\n",
    "# DEFAULT numpy print settings\n",
    "#np.set_printoptions(edgeitems=3,infstr='inf',linewidth=75, nanstr='nan', precision=8,suppress=False, \\\n",
    "#                    threshold=1000, formatter=None)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# dictionaries (Cardelli et al. variable Rv value)\n",
    "# Note: Teff is column 1, log(g) is column 2\n",
    "print '****Creating arrays****'\n",
    "print '****Separating data into arrays by log(g) values****'\n",
    "\n",
    "all_combs_Ax_Av_dict = {}\n",
    "for dataset_key in all_combs_Av0_dict:\n",
    "    Av0_logg_fix = grid_vals_dict(all_combs_Av0_dict[dataset_key],2)\n",
    "    Av1_logg_fix = grid_vals_dict(all_combs_Av1_dict[dataset_key],2)\n",
    "    all_combs_Ax_Av_dict[dataset_key] = diff_grid_dict(Av0_logg_fix,Av1_logg_fix)\n",
    "    print dataset_key, type(key)\n",
    "    \n",
    "print '\\n'\n",
    "for key in all_combs_Ax_Av_dict['3.1,FeH0.0:acs']:\n",
    "    print key, type(all_combs_Ax_Av_dict['3.1,FeH0.0:acs']),type(all_combs_Ax_Av_dict['3.1,FeH0.0:acs'][key])\n",
    "\n",
    "# key style: '3.1,FeH-2.0,acs'\n",
    "ACS_Ax_Av_dict = {}\n",
    "comb_Ax_Av_dict = {}\n",
    "\n",
    "for key in all_combs_Ax_Av_dict:\n",
    "    find_Rv_val = re.search('(.*),FeH',key)\n",
    "    if find_Rv_val:\n",
    "        found_Rv = str(find_Rv_val.group(1))\n",
    "    find_metal = re.search(',FeH(.+?):',key)\n",
    "    if find_metal:\n",
    "        found_metal = str(find_metal.group(1))\n",
    "    find_sys = re.search(':(.*)',key)\n",
    "    if find_sys:\n",
    "        found_sys = str(find_sys.group(1))\n",
    "    \n",
    "    if (found_sys == 'acs'):\n",
    "        ACS_Ax_Av_dict[found_Rv+','+found_metal] = all_combs_Ax_Av_dict[key]\n",
    "    else:\n",
    "        comb_Ax_Av_dict[found_Rv+','+found_metal] = combine_filter_systems_dict(all_combs_Ax_Av_dict[found_Rv+',FeH'+found_metal+':wfc3'],all_combs_Ax_Av_dict[found_Rv+',FeH'+found_metal+':gaia'])\n",
    "\n",
    "for key in comb_Ax_Av_dict:\n",
    "    print key, type(comb_Ax_Av_dict[key])\n",
    "print len(comb_Ax_Av_dict)\n",
    "\n",
    "'''    \n",
    "# Zsolar\n",
    "Av0zs_logg_fix = grid_vals_dict(Av0zs_data,2)\n",
    "Av1zs_logg_fix = grid_vals_dict(Av1zs_data,2)\n",
    "\n",
    "\n",
    "print '****Separating data into arrays by Teff values****'\n",
    "\n",
    "# Zsolar\n",
    "Av0zs_Teff_fix = grid_vals_dict(Av0zs_data,1)\n",
    "Av1zs_Teff_fix = grid_vals_dict(Av1zs_data,1)\n",
    "\n",
    "print '****Finished arrays****'\n",
    "\n",
    "# Final input data form: Ax/Av extinction ratios\n",
    "Agaia_zs = diff_grid_dict(Av0zs_logg_fix,Av1zs_logg_fix)\n",
    "Agaia_z2 = diff_grid_dict(Av0z2_logg_fix,Av1z2_logg_fix)\n",
    "Agaia_z1 = diff_grid_dict(Av0z1_logg_fix,Av1z1_logg_fix)\n",
    "Agaia_zh = diff_grid_dict(Av0zh_logg_fix,Av1zh_logg_fix)\n",
    "\n",
    "Agaia_zs_Teff_fix = diff_grid_dict(Av0zs_Teff_fix,Av1zs_Teff_fix)\n",
    "Agaia_z2_Teff_fix = diff_grid_dict(Av0z2_Teff_fix,Av1z2_Teff_fix)\n",
    "Agaia_z1_Teff_fix = diff_grid_dict(Av0z1_Teff_fix,Av1z1_Teff_fix)\n",
    "Agaia_zh_Teff_fix = diff_grid_dict(Av0zh_Teff_fix,Av1zh_Teff_fix)\n",
    "\n",
    "var_names = ['$T_{eff}$ / K','log($g$ / cm s$^{-2}$)','$A(G)/A(V)$','$A(G_{bp})/A(V)$','$A(G_{rp})/A(V)$','log($T_{eff}$ / K)']\n",
    "   \n",
    "\n",
    "\n",
    "Ahub_zs_Teff_fix = diff_grid_dict(Av0zs_Teff_fix,Av1zs_Teff_fix)\n",
    "Ahub_z2_Teff_fix = diff_grid_dict(Av0z2_Teff_fix,Av1z2_Teff_fix)\n",
    "Ahub_z1_Teff_fix = diff_grid_dict(Av0z1_Teff_fix,Av1z1_Teff_fix)\n",
    "Ahub_zh_Teff_fix = diff_grid_dict(Av0zh_Teff_fix,Av1zh_Teff_fix)\n",
    "\n",
    "print '****Finished arrays****'\n",
    "\n",
    "# N.B.: using cgs unit\n",
    "print 'ACS Hubble data read'\n",
    "print '\\n'\n",
    "ACS_dict_zs = diff_grid_dict(Av0zs_logg_fix,Av1zs_logg_fix)\n",
    "ACS_dict_z2 = diff_grid_dict(Av0z2_logg_fix,Av1z2_logg_fix)\n",
    "ACS_dict_z1 = diff_grid_dict(Av0z1_logg_fix,Av1z1_logg_fix)\n",
    "ACS_dict_zh = diff_grid_dict(Av0zh_logg_fix,Av1zh_logg_fix)\n",
    "\n",
    "ACS_dict_zs_4500K = Teff_cutoff_fix_logg_dict(ACS_dict_zs,4500.0)\n",
    "ACS_dict_z2_4500K = Teff_cutoff_fix_logg_dict(ACS_dict_z2,4500.0)\n",
    "ACS_dict_z1_4500K = Teff_cutoff_fix_logg_dict(ACS_dict_z1,4500.0)\n",
    "ACS_dict_zh_4500K = Teff_cutoff_fix_logg_dict(ACS_dict_zh,4500.0)\n",
    "\n",
    "print '4500K cutoff ACS dict data shape: '\n",
    "for key in sorted(ACS_dict_zs_4500K.iterkeys()):\n",
    "    print ACS_dict_zs_4500K[key].shape\n",
    "\n",
    "print '****Finished arrays****'\n",
    "\n",
    "# combined (Hubble-WFC3 + Gaia) data dictionaries of arrays at fixed log(g) [default format!!!] and different fixed Z values\n",
    "comb_dict_zs = combine_filter_systems_dict(Ahub_zs,Agaia_zs)\n",
    "comb_dict_z2 = combine_filter_systems_dict(Ahub_z2,Agaia_z2)\n",
    "comb_dict_z1 = combine_filter_systems_dict(Ahub_z1,Agaia_z1)\n",
    "comb_dict_zh = combine_filter_systems_dict(Ahub_zh,Agaia_zh)\n",
    "\n",
    "# Avoid tailflick filter artifacts: need Teff cutoff!\n",
    "# log(g)-keyed dictionaries\n",
    "comb_dict_zs_4500K = Teff_cutoff_fix_logg_dict(comb_dict_zs,4500.0)\n",
    "comb_dict_z2_4500K = Teff_cutoff_fix_logg_dict(comb_dict_z2,4500.0)\n",
    "comb_dict_z1_4500K = Teff_cutoff_fix_logg_dict(comb_dict_z1,4500.0)\n",
    "comb_dict_zh_4500K = Teff_cutoff_fix_logg_dict(comb_dict_zh,4500.0)\n",
    "\n",
    "# write out array of combined Hubble & Gaia data\n",
    "#with open('Acombined_vals_solar_gfix','w') as f:\n",
    "#    for key in comb_dict_zs:\n",
    "#        f.write('log(g) = ' + key + ', Z=Zsol')\n",
    "#        f.write(comb_dict_zs[key])\n",
    "        \n",
    "        \n",
    "print type(comb_dict_zs),type(comb_dict_zs['0.0'])\n",
    "print comb_dict_zs['0.0'].shape\n",
    "print len(comb_dict_zs)\n",
    "\n",
    "print comb_dict_Teff_zs['5000.0'].shape\n",
    "print len(comb_dict_Teff_zs)\n",
    "print '4500K cutoff combined dict data shape: '\n",
    "for key in sorted(comb_dict_zs_4500K.iterkeys()):\n",
    "    print comb_dict_zs_4500K[key].shape\n",
    "    \n",
    "#print '4000K cutoff dict data shape: '\n",
    "#for key in sorted(comb_dict_zs_4000K.iterkeys()):\n",
    "#    print comb_dict_zs_4000K[key].shape\n",
    "\n",
    "'''\n",
    "var_names = ['$T_{eff}$ / K','log($g$ / cm s$^{-2}$)','$A(f218w)/A(V)$','$A(f225w)/A(V)$','$A(f275w)/A(V)$','$A(f300x)/A(V)$','$A(f336w)/A(V)$','$A(f390w)/A(V)$','$A(f438w)/A(V)$','$A(f475w)/A(V)$','$A(f555w)/A(V)$','$A(f606w)/A(V)$','$A(f625w)/A(V)$','$A(f775w)/A(V)$','$A(f814w)/A(V)$']\n",
    "\n",
    "# 'log($T_{eff}$ / K)'\n",
    "\n",
    "# filter string names\n",
    "wfc3_filter_str = ['f218w','f225w','f275w','f300x','f336w','f390w','f438w','f475w','f555w','f606w','f625w','f775w','f814w']\n",
    "gaia_filter_str = ['G','Gbp','Grp']\n",
    "comb_filter_str = wfc3_filter_str + gaia_filter_str\n",
    "print 'WFC3+gaia filter labels length: ',len(comb_filter_str)\n",
    "\n",
    "var_names_comb = ['$T_{eff}$ / K','log($g$ / cm s$^{-2}$)','$A(f218w)/A(V)$','$A(f225w)/A(V)$','$A(f275w)/A(V)$',\\\n",
    "                  '$A(f300x)/A(V)$','$A(f336w)/A(V)$','$A(f390w)/A(V)$','$A(f438w)/A(V)$','$A(f475w)/A(V)$',\\\n",
    "                  '$A(f555w)/A(V)$','$A(f606w)/A(V)$','$A(f625w)/A(V)$','$A(f775w)/A(V)$','$A(f814w)/A(V)$',\\\n",
    "                  '$A(G)/A(V)$','$A(G_{bp})/A(V)$','$A(G_{rp})/A(V)$']\n",
    "var_names_ACS = ['$T_{eff}$ / K','log($g$ / cm s$^{-2}$)','$A(f435w)/A(V)$','$A(f475w)/A(V)$','$A(f555w)/A(V)$',\\\n",
    "                 '$A(f606w)/A(V)$','$A(f625w)/A(V)$','$A(f775w)/A(V)$','$A(f814w)/A(V)$']\n",
    "\n",
    "\n",
    "acs_filter_str = ['f435w ACS','f475w ACS','f555w ACS','f606w ACS','f625w ACS','f775w ACS','f814w ACS']\n",
    "print 'ACS filter labels length: ',len(acs_filter_str)\n",
    "\n",
    "print 'Variable data arrays organized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[[  3.5000e+03   0.0000e+00   9.1683e-01   6.7894e-01   8.0363e-01\n",
      "    1.1425e+00   1.2655e+00   1.2002e+00   1.1606e+00   1.0675e+00\n",
      "    9.8907e-01   9.0805e-01   8.8479e-01   7.1482e-01   6.6149e-01\n",
      "    7.3738e-01   9.6549e-01   6.7001e-01]\n",
      " [  3.7500e+03   0.0000e+00   9.7078e-01   7.1555e-01   8.5394e-01\n",
      "    1.1623e+00   1.2656e+00   1.1989e+00   1.1580e+00   1.0682e+00\n",
      "    9.9049e-01   9.1245e-01   8.8883e-01   7.2034e-01   6.7041e-01\n",
      "    7.7486e-01   9.6736e-01   6.9023e-01]\n",
      " [  4.0000e+03   0.0000e+00   1.0190e+00   7.4255e-01   9.0415e-01\n",
      "    1.1971e+00   1.2672e+00   1.2002e+00   1.1590e+00   1.0706e+00\n",
      "    9.9553e-01   9.1795e-01   8.9115e-01   7.2298e-01   6.7481e-01\n",
      "    7.9549e-01   9.7416e-01   6.9939e-01]\n",
      " [  4.2500e+03   0.0000e+00   1.0570e+00   7.7612e-01   1.0450e+00\n",
      "    1.2261e+00   1.2677e+00   1.2032e+00   1.1607e+00   1.0735e+00\n",
      "    9.9977e-01   9.2248e-01   8.9292e-01   7.2431e-01   6.7739e-01\n",
      "    8.0988e-01   9.8066e-01   7.0469e-01]\n",
      " [  4.5000e+03   0.0000e+00   1.0856e+00   8.5681e-01   1.1978e+00\n",
      "    1.2409e+00   1.2679e+00   1.2063e+00   1.1624e+00   1.0765e+00\n",
      "    1.0031e+00   9.2575e-01   8.9418e-01   7.2518e-01   6.7936e-01\n",
      "    8.2098e-01   9.8643e-01   7.0855e-01]\n",
      " [  4.7500e+03   0.0000e+00   1.1189e+00   1.0128e+00   1.2440e+00\n",
      "    1.2487e+00   1.2680e+00   1.2089e+00   1.1642e+00   1.0798e+00\n",
      "    1.0063e+00   9.2859e-01   8.9520e-01   7.2576e-01   6.8086e-01\n",
      "    8.3059e-01   9.9248e-01   7.1136e-01]\n",
      " [  5.0000e+03   0.0000e+00   1.1905e+00   1.1646e+00   1.2576e+00\n",
      "    1.2531e+00   1.2680e+00   1.2109e+00   1.1661e+00   1.0834e+00\n",
      "    1.0096e+00   9.3156e-01   8.9622e-01   7.2616e-01   6.8187e-01\n",
      "    8.4013e-01   9.9922e-01   7.1341e-01]\n",
      " [  5.2500e+03   0.0000e+00   1.2651e+00   1.2568e+00   1.2638e+00\n",
      "    1.2559e+00   1.2680e+00   1.2124e+00   1.1679e+00   1.0872e+00\n",
      "    1.0130e+00   9.3475e-01   8.9736e-01   7.2658e-01   6.8260e-01\n",
      "    8.5048e-01   1.0065e+00   7.1517e-01]\n",
      " [  5.5000e+03   0.0000e+00   1.3258e+00   1.3109e+00   1.2680e+00\n",
      "    1.2579e+00   1.2678e+00   1.2136e+00   1.1697e+00   1.0909e+00\n",
      "    1.0162e+00   9.3803e-01   8.9856e-01   7.2705e-01   6.8318e-01\n",
      "    8.6163e-01   1.0140e+00   7.1685e-01]\n",
      " [  5.7500e+03   0.0000e+00   1.3857e+00   1.3493e+00   1.2717e+00\n",
      "    1.2598e+00   1.2676e+00   1.2146e+00   1.1712e+00   1.0944e+00\n",
      "    1.0193e+00   9.4124e-01   8.9975e-01   7.2755e-01   6.8360e-01\n",
      "    8.7291e-01   1.0213e+00   7.1836e-01]\n",
      " [  6.0000e+03   0.0000e+00   1.4376e+00   1.3780e+00   1.2752e+00\n",
      "    1.2617e+00   1.2674e+00   1.2155e+00   1.1726e+00   1.0978e+00\n",
      "    1.0223e+00   9.4433e-01   9.0089e-01   7.2804e-01   6.8386e-01\n",
      "    8.8420e-01   1.0285e+00   7.1964e-01]]\n"
     ]
    }
   ],
   "source": [
    "print len(comb_Ax_Av_dict['6.0,0.0']['0.0'][0,:])\n",
    "print comb_Ax_Av_dict['6.0,0.0']['0.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APRIL 2019: for thesis, just need data: no fits!\n",
    "# Change font sizes to makes figure legends and axes labels bigger\n",
    "# NOTE: 10 pt is the default standard font size\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=16)    # legend fontsize\n",
    "\n",
    "\n",
    "def just_fortran_data_plot(data_dict,Rv_metal_key,var_names_comb,folder,graph_fold='',extras='',save_stuff='y',zoom_min=None,zoom_max=None):\n",
    "    find_Rv = re.search('(.*),',Rv_metal_key)\n",
    "    if find_Rv:\n",
    "        Rv = str(find_Rv.group(1))\n",
    "    find_metal = re.search(',(.*)',Rv_metal_key)\n",
    "    if find_metal:\n",
    "        metal = str(find_metal.group(1))\n",
    "    Rv = Rv.replace('.','p')\n",
    "    metal = metal.replace('.','p')\n",
    "    if ('-' in metal):\n",
    "        metal = metal.replace('-','m')\n",
    "    if ( (zoom_min is not None) and (zoom_max is not None)):\n",
    "        plot_dir_str_metal = folder + '/' + graph_fold + '/Ax_Av_FeH' + metal + '_just_Teff_plot_' + str(zoom_min) + '_' + str(zoom_max) + extras + '.pdf'\n",
    "    else:\n",
    "        plot_dir_str_metal = folder + '/' + graph_fold + '/Ax_Av_FeH' + metal + '_just_Teff_plot' + extras + '.pdf'\n",
    "    if (len(data_dict['5.0'][0,:]) > 11):\n",
    "        fig, axs = plt.subplots(nrows=4,ncols=4,figsize=(16, 16))\n",
    "        Nrows = 4\n",
    "        Ncols = 4\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nrows=3,ncols=3,figsize=(16, 16))\n",
    "        Nrows = 3\n",
    "        Ncols = 3\n",
    "    axs = axs.ravel()\n",
    "    # Write out to new file: first 'with' statement empties the file to be written into later\n",
    "    # Iteration for changes BETWEEN filters !!!\n",
    "    for i in range(2,len(data_dict['5.0'][0,:])):\n",
    "        axs[i-2].set_xlabel(var_names_comb[0])\n",
    "        axs[i-2].set_ylabel(var_names_comb[i])\n",
    "        for keyval in reversed(sorted(data_dict.iterkeys())):\n",
    "            A_X_chosen = data_dict[keyval]\n",
    "            axs[i-2].plot(A_X_chosen[:,0],A_X_chosen[:,i],marker='',linestyle='-',label='log(g) = '+keyval)#,marker='x',linestyle='--'\n",
    "            if ( (zoom_min is not None) and (zoom_max is not None)):\n",
    "                axs[i-2].set_xlim(zoom_min,zoom_max)\n",
    "    if ( (len(data_dict['5.0'][0,:]) - 2) < (Nrows*Ncols) ):\n",
    "        print 'Deleting missing subplots - discrepancy between ' + str(len(data_dict['5.0'][0,:]) - 2) + ' and ' + str(Nrows*Ncols)\n",
    "        for d in range((len(data_dict['5.0'][0,:]) - 2),(Nrows*Ncols)):\n",
    "            fig.delaxes(axs[d])\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    if (save_stuff == 'y'):\n",
    "        fig.savefig(plot_dir_str_metal, bbox_inches='tight')\n",
    "\n",
    "folder_str = 'Rv_varied'\n",
    "for Rz_key in comb_Ax_Av_dict:\n",
    "    comb_Ax_Av_dict(comb_dict_allZ,Rz_key,var_names_comb,folder_str+'/just_full_data',extras='_comb_lines')#,zoom_min=3000,zoom_max=15000)\n",
    "    just_fortran_data_plot(ACS_dict_allZ,Rz_key,var_names_ACS,folder_str+'/just_full_data',extras='_ACS_lines')#,zoom_min=3000,zoom_max=15000)\n",
    "    #,save_stuff='n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
