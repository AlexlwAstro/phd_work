{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions, modules done\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "#%matplotlib notebook\n",
    "#%pylab\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import fileinput\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import CubicSpline\n",
    "import scipy.special as scs\n",
    "from scipy.stats import norm\n",
    "import operator\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colorbar as cobar\n",
    "\n",
    "# Change font sizes to makes figure legends and axes labels bigger\n",
    "# NOTE: 10 pt is the default standard font size\n",
    "plt.rc('axes', labelsize=16)    # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=16)    # legend fontsize\n",
    "\n",
    "# function to change OUTPUT file into space-separated float fields and parameterise the data using this new format\n",
    "# line in 'with open' bit is type 'str'\n",
    "\n",
    "# create a function to get spectral grid data\n",
    "\n",
    "oldstr = ['0-','1-','2-','3-','4-','5-','6-','7-','8-','9-']\n",
    "newstr = ['0 -','1 -','2 -','3 -','4 -','5 -','6 -','7 -','8 -','9 -']\n",
    "\n",
    "def data_read_gaia(f):\n",
    "    # GENERAL PYTHON DATA READ FUNCTION!!!\n",
    "    missed_line_inds = []\n",
    "    temp_data = []\n",
    "    check = 0\n",
    "    #number of lines to cut = number of line containing 'convective shell' label - (2 + any additional string lines)\n",
    "    for line in f:\n",
    "        for i in range(len(oldstr)):\n",
    "            line = line.replace(oldstr[i],newstr[i])\n",
    "        check = check + 1\n",
    "        for x in range(10,1,-1):\n",
    "            line = line.replace((x*' '),' ')\n",
    "        line = line.replace('D','E')\n",
    "        match_ast = re.search('[**]', line)\n",
    "        match_inf = re.search('Infinity',line)\n",
    "        match_hash = re.search('#',line)\n",
    "        if match_ast or match_inf or match_hash or (line.strip()==''):\n",
    "            missed_line_inds.append(check)\n",
    "        else:\n",
    "            file_data = np.array([float(parameter) for parameter in line.strip().split(' ')])\n",
    "            temp_data.append(file_data)\n",
    "    out_all_data = np.array(temp_data)\n",
    "\n",
    "    print 'Total dataset: ',out_all_data.shape\n",
    "    return out_all_data\n",
    "\n",
    "# select the parameter (Teff or log(g) for each array(file)) with which to analyse the filter profiles,\n",
    "# by setting the other to be constant, using the column number (integer)\n",
    "def grid_vals_dict(input_arr,col_numb):\n",
    "    col_vals = []\n",
    "    col_var_arrs = {}\n",
    "    # create list of values of the column NOT being examined\n",
    "    for i in range(len(input_arr[:,(col_numb - 1)])):\n",
    "        if (input_arr[i,(col_numb - 1)] not in col_vals):\n",
    "            col_vals.append(input_arr[i,(col_numb - 1)])\n",
    "    print 'Table column ',col_numb,' values list: ',col_vals\n",
    "    # create arrays for fixed values of col_numb parameter\n",
    "    for j in col_vals:\n",
    "        temp_k_list = []\n",
    "        for k in range(len(input_arr[:,(col_numb - 1)])):\n",
    "            if (input_arr[k,(col_numb - 1)] == j):\n",
    "                temp_k_list.append(input_arr[k,:])\n",
    "        temp_k_array = np.array(temp_k_list)\n",
    "        #print 'For column',col_numb,'value of',j,', the array has the following shape: ',temp_k_array.shape\n",
    "        col_var_arrs[str(j)] = temp_k_array\n",
    "    print 'Final dictionary length: ',len(col_var_arrs)\n",
    "    return col_var_arrs, col_vals\n",
    "\n",
    "   \n",
    "def diff_grid_dict(dict_Av0,dict_Avne0):\n",
    "    diff_dict = {}\n",
    "    # use sets to match keys in dictionaries\n",
    "    combined_set = set(dict_Av0).intersection(set(dict_Avne0))\n",
    "    print 'combined set size:',len(combined_set)\n",
    "    for key_val in combined_set:\n",
    "        #print key_val\n",
    "        # use variables to store each key value\n",
    "        Av0_arr_kv = dict_Av0[key_val]\n",
    "        Avne0_arr_kv = dict_Avne0[key_val]\n",
    "        # take the difference of the two sets of filter magnitudes for different calibrations of BCs\n",
    "        # gives absolute extinction A(X) as numerical output\n",
    "        diff_arr_kv = Av0_arr_kv - Avne0_arr_kv\n",
    "        for n in range(len(diff_arr_kv[0,:])):\n",
    "            if (n == 0 or n == 1):\n",
    "                # these columns are Teff, log(g) - the inputs for the grid - need to reset these to recover grid\n",
    "                diff_arr_kv[:,n] = Av0_arr_kv[:,n]\n",
    "        diff_dict[key_val] = diff_arr_kv\n",
    "        if (diff_arr_kv.shape != Avne0_arr_kv.shape):\n",
    "            print 'shape error'\n",
    "    print 'Raw A(X) dictionary complete'\n",
    "    return diff_dict\n",
    "\n",
    "\n",
    "# general fits write-out function\n",
    "\n",
    "def general_fit_number_gen_write(f,func_type,func_coeffs,covar_matrix,filter_str,logg_val,avg_dict):\n",
    "    frac_list = []\n",
    "    output_names = ['    Fit coefficients (in order of functions'' arguments):','    Standard deviations:']\n",
    "    f.write('Fitting results for ' + str(filter_str) + ' filter, with log(g) = ' + str(logg_val) + '\\n')\n",
    "    f.write('Function type:  ' + func_type + '\\n')\n",
    "    f.write(output_names[0] + '\\n')\n",
    "    f.write(str(func_coeffs) + '\\n')\n",
    "    f.write(output_names[1] + '\\n')\n",
    "    f.write(str(covar_matrix) + '\\n')\n",
    "    f.write('Fractional errors in fit coefficients = {E[(X(i)-E[X(i)])*(X(j)-E[X(j)])]}/{|E[X(i)]*E[X(j)]|}' + '\\n')\n",
    "    f.write('i.e., covariance(i,j)/{coef(i)*coef(j)}' + 2*'\\n')\n",
    "    f.write('Fractional error output:  ' + '\\n')\n",
    "    # write out errors as detailed above\n",
    "    \n",
    "    sum_y = 0\n",
    "    yterm_count = 0\n",
    "    for i in range(len(func_coeffs)):\n",
    "        f.write('row ' + str(i+1) + 2*'\\t')\n",
    "        # use if statement to avoid repeating terms in symmetrical covariance matrix\n",
    "        # should result in increasing number of entries for increasing row number\n",
    "        y = abs(covar_matrix[i]/func_coeffs[i])\n",
    "        f.write(str(y) + '\\t')\n",
    "        yterm_count += 1\n",
    "        sum_y += y\n",
    "        f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    avg_y = sum_y/yterm_count\n",
    "    avg_dict[func_type] = avg_y\n",
    "    f.write('Average fractional error = ' + str(avg_y) + 2*'\\n')\n",
    "    print 'Average fractional error for ' + func_type + ' = ' + str(avg_y)\n",
    "    \n",
    "# Modelling functions below!!!\n",
    "\n",
    "# linear function\n",
    "def linear_func(xdata,a,b):\n",
    "    y = (a*xdata) + b\n",
    "    return y\n",
    "\n",
    "# quadratic function\n",
    "def quad_func(xdata,a,b,c):\n",
    "    y = a*(xdata**2) + (b*xdata) + c\n",
    "    return y\n",
    "\n",
    "# single power-law term\n",
    "def single_poly(xdata,a,b,c):\n",
    "    y = a*((1.0e-04*xdata)**b) + c\n",
    "    return y\n",
    "\n",
    "# exponential function\n",
    "def exp_func(xdata,a,b,c):\n",
    "    y = a*(np.exp(b*(1.0e-04*xdata))) + c\n",
    "    return y\n",
    "\n",
    "# logarithmic function\n",
    "def log_func(xdata,a,b,c):\n",
    "    y = (a*(np.log10(b*xdata))) + c\n",
    "    return y\n",
    "\n",
    "# Teff & logg quadratic-like function\n",
    "# Need y = 0 at Teff cut-off value -> put (Tcut-Tdata) at front\n",
    "def Teff_logg_product_func(Tdata,Tcut,gdata,ind,a,b,c): #,d\n",
    "    y = ((Tcut-Tdata)**ind)*(a*(5.0-gdata)**b) + c #*(5.0-gdata)**(b-1)) + d\n",
    "    return y\n",
    "\n",
    "#polyfit_coeffs,polyfit_cov = (Tdata-Tcut),Aratio_data,deg\n",
    "\n",
    "# try to get compensatory functions\n",
    "# To avoid non-convergence\n",
    "def Teff_logg_polynomial(Tdata,Tcut,gdata,a,b,c=0.0,d=2):\n",
    "    # note: want b (power) to be integer!\n",
    "    y = ((a*(Tcut-Tdata)**d + b*(Tcut-Tdata)**(d-1))*(5.0-gdata)) + c\n",
    "    return y\n",
    "\n",
    "# Teff, metallicity & logg quadratic-like function\n",
    "def Teff_logg_metal_product_func(Tdata,gdata,metal_val,a,b,c=0.0,d=2):\n",
    "    # assuming Zsolar = 0.0172\n",
    "    y = ((a*(Tcut-Tdata)**d + b*(Tcut-Tdata)**(d-1))*(5.0-gdata)) + c\n",
    "    #y = a*(Tdata*gdata) + b*(gdata**2) + c + d*((0.0172 - metal_val)*Tdata)\n",
    "    return y\n",
    "\n",
    "# Full addition of exponential function to power-law\n",
    "def full_pow_plus_exp_func(xdata,a,b,c,d,e):\n",
    "    y = (d*(xdata**e)) + (a*(np.exp(b*xdata))) + c\n",
    "    return y\n",
    "\n",
    "\"\"\"\n",
    "maybe use underdamped oscillation as solution? With log(g), Z related to the value of the damping ratio, G?\n",
    "For underdamped systems, 0 < G < 1\n",
    "Approach: change in Ax/Av, call x, has solution x = C*exp(st)\n",
    "where s = -w_n * (G +/- i*sqrt(1 - G^2))\n",
    "NumPy: 'j' is the character used for imaginary numbers\n",
    "\"\"\"\n",
    "# PROBLEM: if zeta2**2 > 1, gives nan rather than evaluating two imaginary numbers!\n",
    "# Note: General solution is linear sum of terms!\n",
    "def decay_coeff_nan_avoid(omega,zeta,RIF=1.0):\n",
    "    if (abs(zeta) <= 1.0):\n",
    "        s1 = -omega*( zeta + RIF*1.0j*np.sqrt(1-zeta**2) ) #r*\n",
    "        s2 = -omega*( zeta - RIF*1.0j*np.sqrt(1-zeta**2) )\n",
    "    else:\n",
    "        s1 = -omega*( zeta - RIF*np.sqrt((zeta**2) - 1) ) #r* #r*\n",
    "        s2 = -omega*( zeta + RIF*np.sqrt((zeta**2) - 1) )\n",
    "    return s1,s2\n",
    "\n",
    "def damped_oscillator_gZ(input_params,Tmax,a,b,c,d,f,k,r):\n",
    "    # Free parameters are: a,b,c,d,k,r ,m\n",
    "    if type(input_params) is tuple:\n",
    "        # if 'input_params' is a tuple\n",
    "        Tdata,gdata,zdata = input_params\n",
    "        #print 'input_params is a tuple'\n",
    "        #print Tdata.shape,gdata.shape,zdata.shape\n",
    "    elif type(input_params) is np.ndarray:\n",
    "        # if 'input_params' is an array\n",
    "        Tdata,gdata,zdata = input_params\n",
    "        #print 'input_params is an array'\n",
    "        #print input_params[0,:]\n",
    "        #print Tdata.shape,gdata.shape,zdata.shape\n",
    "    \n",
    "    # exponential damping coefficient s, function of zeta, the damping ratio\n",
    "    # need zeta = zeta(g,Z)\n",
    "    zeta = a*(5.0-gdata)**2 + b*zdata + c\n",
    "    s1 = np.empty_like(zeta)\n",
    "    s2 = np.empty_like(zeta)\n",
    "    # calculate s for each element in zeta array\n",
    "    for i in range(len(zeta)):\n",
    "        zeta_elem = zeta[i]\n",
    "        s1[i],s2[i] = decay_coeff_nan_avoid(d,zeta_elem,f)\n",
    "    \n",
    "    # 'Tdata' called below! - this should remove the need to use it anywhere in 'zeta'\n",
    "    \n",
    "    new_var = k*(np.exp(s1*(Tdata-Tmax)*1.0e-04) + np.exp(s2*(Tdata-Tmax)*1.0e-04)) + r\n",
    "    return new_var\n",
    "\n",
    "# General damped oscillator - fit for all combinations with Teff only, then find trends for g, Z in output numbers\n",
    "def orig_damped_oscillator_gZ(Tdata,Tref,zeta,d,k,m,r):\n",
    "    # Free parameters are: zeta,d,k,m,r\n",
    "    \n",
    "    # exponential damping coefficient s1,s2, function of zeta, the damping ratio\n",
    "    s1,s2 = decay_coeff_nan_avoid(d,zeta)\n",
    "    new_var = k*np.exp(s1*(Tdata-Tref)*1.0e-04) + m*np.exp(s2*(Tdata-Tref)*1.0e-04) + r\n",
    "    return new_var.real\n",
    "\n",
    "def simp_damped_oscillator_gZ(Tdata,Tref,zeta,d,k,f,r):\n",
    "    # Free parameters are: zeta,d,k,m,r\n",
    "    \n",
    "    # exponential damping coefficient s1,s2, function of zeta, the damping ratio\n",
    "    s1,s2 = decay_coeff_nan_avoid(d,zeta,f)\n",
    "    new_var = np.real(k*(np.exp(s1*(Tdata-Tref)*1.0e-04) + np.exp(s2*(Tdata-Tref)*1.0e-04)) + r)\n",
    "    return new_var\n",
    "\n",
    "def weighted_damped_oscillator_gZ(input_params,Tcut,a,b,c,d,k,r):\n",
    "    # Free parameters are: a,b,c,d,k,r\n",
    "    if type(input_params) is tuple:\n",
    "        # if 'input_params' is a tuple\n",
    "        Tdata,gdata,zdata = input_params\n",
    "        #print 'input_params is a tuple'\n",
    "        #print Tdata.shape,gdata.shape,zdata.shape\n",
    "    elif type(input_params) is np.ndarray:\n",
    "        # if 'input_params' is an array\n",
    "        Tdata,gdata,zdata = input_params\n",
    "        #print 'input_params is an array'\n",
    "        #print input_params[0,:]\n",
    "        #print Tdata.shape,gdata.shape,zdata.shape\n",
    "    \n",
    "    # exponential damping coefficient s, function of zeta, the damping ratio\n",
    "    # need zeta = zeta(g,Z)\n",
    "    zeta = a*(5.0-gdata) + b*zdata + c\n",
    "    s1 = np.empty_like(zeta)\n",
    "    s2 = np.empty_like(zeta)\n",
    "    # calculate s for each element in zeta array\n",
    "    for i in range(len(zeta)):\n",
    "        zeta_elem = zeta[i]\n",
    "        s1[i],s2[i] = decay_coeff_nan_avoid(d,zeta_elem)\n",
    "    \n",
    "    # 'Tdata' called below! - this should remove the need to use it anywhere in 'zeta'\n",
    "    \n",
    "    #R = a*(Tcut - Tdata)\n",
    "    new_var = (k*(Tcut - Tdata))*( np.exp(s1*(Tdata-Tcut)*1.0e-04) + np.exp(s2*(Tdata-Tcut)*1.0e-04) ) + r\n",
    "    return new_var\n",
    "\n",
    "\n",
    "def coeffs_tinker_store(data_arr,Tmax,g,z,d,zeta,k,r,filter_str,list_out,file_out=None):\n",
    "    # Manually set d,zeta,k,r (Tmax = 15,000K)\n",
    "    s1,s2 = decay_coeff_nan_avoid(d,zeta)\n",
    "    dosc_out = k*( np.exp(s1*(data_arr[:,0]-Tmax)*1.0e-04) + np.exp(s2*(data_arr[:,0]-Tmax)*1.0e-04) ) + r\n",
    "    coeffs_1g1z = [k,s1,s2,r]\n",
    "    if (file_out is not None):\n",
    "        with open(file_out,'a') as f:\n",
    "            f.write('Filter: '+filter_str+'\\n')\n",
    "            f.write('Coordinates: g = '+g+', z = '+str(z)+', Tmax = 15000K\\n')\n",
    "            f.write('Coefficients for damped oscillator function (k*exp(s*(Tmax-Teff)) + r): \\n')\n",
    "            f.write(str(coeffs_1g1z)+2*'\\n')\n",
    "            f.close()\n",
    "    list_out.append(coeffs_1g1z)\n",
    "    return dosc_out,coeffs_1g1z\n",
    "\n",
    "# low-Teff: log(g) affects A(filter)/A(V), i.e. A(Teff) becomes A(Teff,log(g))\n",
    "# -> find law for log(g) effects\n",
    "# N.B.: log(g) = consts. x (M(R*)/(R*)^2)\n",
    "# Linear? Girardi et al. (2008) use giant Teff law: Teff(log(g)) = 3250 + 500log(g)\n",
    "# For my values of log(g) (= 0 to 5), this gives a range of (3250 <= Teff <= 5750)\n",
    "# Take our working definition of 0.01 'error' as a limit on log(g) effects\n",
    "\n",
    "\n",
    "# need to combine some effects of Teff, log(g)\n",
    "# use Teff-keyed dictionaries as the dataset\n",
    "def from_keys_get_numerical_data(input_dict):\n",
    "    key_vals_list = []\n",
    "    for key in sorted(input_dict.iterkeys()):\n",
    "        float_key = float(key)\n",
    "        key_vals_list.append(float_key)\n",
    "    \n",
    "    key_vals_arr = np.array(key_vals_list)\n",
    "    print 'Array of key values: ', key_vals_arr.shape\n",
    "    return key_vals_arr\n",
    "\n",
    "\n",
    "# try a function to reduce oppportunities for error for stuff below\n",
    "# during curve fitting - tests, plots & writes out figure, writes out results of covariance matrix analysis\n",
    "\n",
    "# define the actual load-up of the functions to be fitted separately\n",
    "def functions_loadup(function,x_coords_fit,y_coords_fit,bounds_list,coeffs_list,stdev_list,sigma_val,abs_sig='n',p0_opt=None,niter=10000):\n",
    "    # functions_list, bounds_list MUST MATCH in their orders!! (functions and coefficient bounds, respectively)\n",
    "    #for a in functions_list: # iterate between function types\n",
    "    \n",
    "    ab_s_val = False\n",
    "    if (abs_sig != 'n'):\n",
    "        ab_s_val = True\n",
    "    if (sigma_val is not None):\n",
    "        sigmas = np.full(len(x_coords_fit),sigma_val)\n",
    "    else:\n",
    "        sigmas = None\n",
    "    function_coeffs,covarr = curve_fit(function,x_coords_fit,y_coords_fit, p0=p0_opt, sigma=sigmas,bounds=bounds_list,\\\n",
    "                                       absolute_sigma=ab_s_val,max_nfev=niter)\n",
    "    # extract the standard deviation\n",
    "    stdev = np.sqrt(np.diag(covarr))\n",
    "    \n",
    "    coeffs_list.append(function_coeffs)\n",
    "    # cov_arr_list.append(covarr)\n",
    "    stdev_list.append(stdev)\n",
    "    return coeffs_list,stdev_list #,cov_arr_list\n",
    "\n",
    "# Function to extract (unique) values of Ax/Av to place in a 2D-grid system\n",
    "def one_filter_get_grid(inarr,filter_column,Teff_grid,Teff_grid_vals,logg_grid,logg_grid_vals,grids_list,zero_fill='y'):\n",
    "    p = 0\n",
    "    if (zero_fill == 'y'):\n",
    "        Afilter_grid = np.zeros((len(Teff_grid_vals),len(logg_grid_vals)))\n",
    "    else:\n",
    "        Afilter_grid = np.full((len(Teff_grid_vals),len(logg_grid_vals)),np.nan)\n",
    "        #(max(inarr[:,filter_column])+0.00001)\n",
    "        \n",
    "    # Iterate through the grid elements, [i,j]\n",
    "    for i in range(len(Teff_grid[:,0])):\n",
    "        for j in range(len(logg_grid[0,:])):\n",
    "            T_i = Teff_grid[i,0]\n",
    "            g_j = logg_grid[0,j]\n",
    "            # go through the input Ax/Av array [k,x]\n",
    "            for k in range(len(inarr[:,0])):\n",
    "                T_k = inarr[k,0]\n",
    "                g_k = inarr[k,1]\n",
    "                # find matching Teff-log(g) pairs to keep Ax/Av data in the right place\n",
    "                if ( T_i == T_k and g_j == g_k ):\n",
    "                    p += 1\n",
    "                    Afilter_grid[i,j] = np.copy(inarr[k,filter_column])\n",
    "    Afilter_grid = np.around(Afilter_grid,decimals=5)\n",
    "    #print Afilter_grid[0,:]\n",
    "    grids_list.append(Afilter_grid)\n",
    "    return p\n",
    "\n",
    "def TgZ_2D_grid_plot(xgrid,ygrid,Afilters_list,details,z_Tcut_specifiers,fig_size):\n",
    "    fig,conax = plt.subplots(nrows=4,ncols=4,figsize=(fig_size, fig_size))\n",
    "    conax = conax.ravel()\n",
    "\n",
    "    cmap = cm.viridis # set colormap\n",
    "    #norm = plt.Normalize(min(np.amin(x) for x in Afilters_list),max(np.amax(x) for x in Afilters_list))\n",
    "\n",
    "    # NOTE: can treat conax[i] as with any other canvas!\n",
    "    for i in range(len(Afilters_list)):\n",
    "        #max_abs = max(abs(np.amin(Afilters_list[i])),abs(np.amax(Afilters_list[i])))\n",
    "        #norm = plt.Normalize(-max_abs,max_abs)\n",
    "        norm = plt.Normalize(np.amin(Afilters_list[i]),np.amax(Afilters_list[i]))\n",
    "        cont_i = conax[i].contourf(xgrid,ygrid,Afilters_list[i],cmap=cmap,norm=norm)\n",
    "        cbar = plt.colorbar(cont_i,ax=conax[i])\n",
    "        cbar.set_label(var_names_comb[i+2] + ' - $A_{1}(T_{eff})$')\n",
    "        #fig.colorbar(cont_i, ax=conax[i])\n",
    "        conax[i].set_xlim(4500,15000)\n",
    "        fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(details + z_Tcut_specifiers + '.pdf')\n",
    "    print 'Figure saved!'\n",
    "\n",
    "# curve fitting function\n",
    "def filter_curve_fit(dict_chosen,key,exp_bounds,pow_bounds,logis_bounds,plog_bounds,filter_str,sigma_value=None,abs_sigma_yn='n',p0_opt_logis=None,p0_opt_plog=None,niter=10000):\n",
    "    A_X_chosen = dict_chosen[key]\n",
    "    if (key == '5.0'):\n",
    "        # curve-fitting commands - for log(g) = 5.0 ONLY - apply results to other log(g) values\n",
    "        # store using the following lists:\n",
    "        exp_fit_A_logg5_list = []\n",
    "        stdev_A_logg5_ef_list = []\n",
    "        pow_fit_A_logg5_list = []\n",
    "        stdev_A_logg5_pow_list = []\n",
    "        # add logistic fit\n",
    "        logis_fit_A_logg5_list = []\n",
    "        stdev_A_logg5_logis_list = []\n",
    "        # add power-law logistic fit\n",
    "        plog_fit_A_logg5_list = []\n",
    "        stdev_A_logg5_plog_list = []\n",
    "        \n",
    "        exp_comb5_fits_dict = {}\n",
    "        exp_comb5_stdev_dict = {}\n",
    "        pow_comb5_fits_dict = {}\n",
    "        pow_comb5_stdev_dict = {}\n",
    "        logis_comb5_fits_dict = {}\n",
    "        logis_comb5_stdev_dict = {}\n",
    "        plog_comb5_fits_dict = {}\n",
    "        plog_comb5_stdev_dict = {}\n",
    "        \n",
    "        # *** NOTE: 'functions_loadup' is where curve_fit is employed ***\n",
    "        for i in range(2,len(A_X_chosen[0,:])):\n",
    "            functions_loadup(exp_func,A_X_chosen[:,0],A_X_chosen[:,i],exp_bounds[i-2],exp_fit_A_logg5_list,stdev_A_logg5_ef_list,sigma_value,abs_sigma_yn,niter=niter)\n",
    "            functions_loadup(single_poly,A_X_chosen[:,0],A_X_chosen[:,i],pow_bounds[i-2],pow_fit_A_logg5_list,stdev_A_logg5_pow_list,sigma_value,abs_sigma_yn,niter=niter)\n",
    "            functions_loadup(R1_logistic_func,A_X_chosen[:,0],A_X_chosen[:,i],logis_bounds[i-2],logis_fit_A_logg5_list,stdev_A_logg5_logis_list,sigma_value,abs_sigma_yn,p0_opt=p0_opt_logis,niter=niter)\n",
    "            functions_loadup(R1_log_normal_func,A_X_chosen[:,0],A_X_chosen[:,i],plog_bounds[i-2],plog_fit_A_logg5_list,stdev_A_logg5_plog_list,sigma_value,abs_sigma_yn,p0_opt=p0_opt_plog,niter=niter)\n",
    "            \n",
    "            #exp_fit_A_logg5, covarr_A_logg5_ef = curve_fit(exp_func,A_X_chosen[:,0],A_X_chosen[:,i], p0=None, sigma=None,bounds=exp_bounds[i-2])\n",
    "            #pow_fit_A_logg5, covarr_A_logg5_pow = curve_fit(single_poly,A_X_chosen[:,0],A_X_chosen[:,i], p0=None, sigma=None,bounds=pow_bounds[i-2])\n",
    "            #spp_exp_fit_A_logg5, covarr_A_logg5_spp = curve_fit(single_poly_plus_exp_func,A_X_chosen[:,0],A_X_chosen[:,i], p0=None, sigma=None,bounds=spp_bounds[i-2])\n",
    "\n",
    "            exp_fit_A_logg5 = exp_fit_A_logg5_list[i-2]\n",
    "            stdev_A_logg5_ef = stdev_A_logg5_ef_list[i-2]\n",
    "            pow_fit_A_logg5 = pow_fit_A_logg5_list[i-2]\n",
    "            stdev_A_logg5_pow = stdev_A_logg5_pow_list[i-2]\n",
    "            logis_fit_A_logg5 = logis_fit_A_logg5_list[i-2]\n",
    "            stdev_A_logg5_logis = stdev_A_logg5_logis_list[i-2]\n",
    "            plog_fit_A_logg5 = plog_fit_A_logg5_list[i-2]\n",
    "            stdev_A_logg5_plog = stdev_A_logg5_plog_list[i-2]\n",
    "            \n",
    "            # print fitting results\n",
    "            print 'Calculating coefficients & covariance matrices for ' + filter_str[i-2] + ' filter'\n",
    "            \n",
    "            print 'Exponential fit coefficients: '\n",
    "            print exp_fit_A_logg5\n",
    "            print 'Standard deviations: '\n",
    "            print stdev_A_logg5_ef\n",
    "            \n",
    "            exp_comb5_fits_dict[filter_str[i-2]] = exp_fit_A_logg5\n",
    "            exp_comb5_stdev_dict[filter_str[i-2]] = stdev_A_logg5_ef\n",
    "            \n",
    "            print 'Teff^(n) fit coefficients: '\n",
    "            print pow_fit_A_logg5\n",
    "            print 'Standard deviations: '\n",
    "            print stdev_A_logg5_pow\n",
    "            \n",
    "            pow_comb5_fits_dict[filter_str[i-2]] = pow_fit_A_logg5\n",
    "            pow_comb5_stdev_dict[filter_str[i-2]] = stdev_A_logg5_pow\n",
    "\n",
    "            print 'Logistic fit coefficients: '\n",
    "            print logis_fit_A_logg5\n",
    "            print 'Standard deviations: '\n",
    "            print stdev_A_logg5_logis\n",
    "            \n",
    "            logis_comb5_fits_dict[filter_str[i-2]] = logis_fit_A_logg5\n",
    "            logis_comb5_stdev_dict[filter_str[i-2]] = stdev_A_logg5_logis\n",
    "            \n",
    "            print 'Teff log-normal fit coefficients: '\n",
    "            print plog_fit_A_logg5\n",
    "            print 'Standard deviations: '\n",
    "            print stdev_A_logg5_plog\n",
    "            \n",
    "            plog_comb5_fits_dict[filter_str[i-2]] = plog_fit_A_logg5\n",
    "            plog_comb5_stdev_dict[filter_str[i-2]] = stdev_A_logg5_plog\n",
    "            \n",
    "            print 2*'\\n'\n",
    "            \n",
    "        print 'Number of fit operations = ', len(exp_fit_A_logg5_list)\n",
    "        print 'List object type: ', type(exp_fit_A_logg5_list)\n",
    "        # combine lists to store for log(g) != 5.0 function runs\n",
    "        combined_list = [exp_fit_A_logg5_list,stdev_A_logg5_ef_list,pow_fit_A_logg5_list,stdev_A_logg5_pow_list,\\\n",
    "                         logis_fit_A_logg5_list,stdev_A_logg5_logis_list,plog_fit_A_logg5_list,stdev_A_logg5_plog_list]\n",
    "        \n",
    "        comb_dict_list = [exp_comb5_fits_dict,exp_comb5_stdev_dict,pow_comb5_fits_dict,pow_comb5_stdev_dict,\\\n",
    "                          logis_comb5_fits_dict,logis_comb5_stdev_dict,plog_comb5_fits_dict,plog_comb5_stdev_dict]\n",
    "        #print combined_list\n",
    "    print '\\n         FITTING OPERATION COMPLETE \\n'\n",
    "    return combined_list,comb_dict_list\n",
    "\n",
    "\n",
    "# plot & write results\n",
    "def filter_curve_plot_write(A_X_zs_gfix,A_X_z2_gfix,A_X_z1_gfix,A_X_zh_gfix,combined_list,key,metal,extras,filter_str,var_names_comb,sig_val,folder,graph_fold,casa_opt,multiplot_file,plot_diff='n',coef_cut='',write_stuff='n',save_stuff='y',zoom_min=None,zoom_max=None):\n",
    "    if (metal == 'solar'):\n",
    "        A_X_chosen = A_X_zs_gfix[key]\n",
    "        casa_chosen = casa_arr_zs\n",
    "    elif (metal == 'sol_100'):\n",
    "        A_X_chosen = A_X_z2_gfix[key]\n",
    "        casa_chosen = casa_arr_z2\n",
    "    elif (metal == 'sol_10'):\n",
    "        A_X_chosen = A_X_z1_gfix[key]\n",
    "        casa_chosen = casa_arr_z1\n",
    "    elif (metal == 'solx3'):\n",
    "        A_X_chosen = A_X_zh_gfix[key]\n",
    "        casa_chosen = casa_arr_zh\n",
    "    else:\n",
    "        print 'Error! Incorrect metallicity input'\n",
    "        A_X_chosen = []\n",
    "    \n",
    "    if (zoom_min is not None and zoom_max is not None):\n",
    "        extras += ('_zoom_' + str(int(zoom_min)) + 'K_' + str(int(zoom_max)) + 'K')\n",
    "    \n",
    "    # Hubble data: easier to use subplots -> add option\n",
    "    if (multiplot_file == 'y'):\n",
    "        plot_dir_str_i = None\n",
    "        data_dir_str_i = None\n",
    "        if (len(A_X_chosen[0,:]) > 11):\n",
    "            fig, axs = plt.subplots(nrows=4,ncols=4,figsize=(16, 16))\n",
    "            Nrows = 4\n",
    "            Ncols = 4\n",
    "        else:\n",
    "            fig, axs = plt.subplots(nrows=3,ncols=3,figsize=(16, 16))\n",
    "            Nrows = 3\n",
    "            Ncols = 3\n",
    "            \n",
    "        axs = axs.ravel()\n",
    "        # Write out to new file: first 'with' statement empties the file to be written into later\n",
    "        data_dir_str_i = folder + '/Teff_AHub_gaia_gen_fit_logg=' + key + '_' + metal + '_' + extras + '_numbers.txt'\n",
    "        if (write_stuff == 'y' and key == '5.0' and metal == 'solar'):\n",
    "            with open (data_dir_str_i,'w') as f:\n",
    "                f.close()\n",
    "        # Iteration for changes BETWEEN filters !!!\n",
    "        for i in range(2,len(A_X_chosen[0,:])):\n",
    "            # curve-fitting commands - for log(g) = 5.0 ONLY - apply results to other log(g) values\n",
    "            # use lists filled in before (for log(g) = 5.0) to provide fit-curve data\n",
    "            exp_fit_A_logg5 = (combined_list[0])[i-2]\n",
    "            stdev_A_logg5_ef = (combined_list[1])[i-2]\n",
    "            pow_fit_A_logg5 = (combined_list[2])[i-2]\n",
    "            stdev_A_logg5_pow = (combined_list[3])[i-2]\n",
    "            logis_fit_A_logg5 = (combined_list[4])[i-2]\n",
    "            stdev_A_logg5_logis = (combined_list[5])[i-2]\n",
    "            plog_fit_A_logg5 = (combined_list[6])[i-2]\n",
    "            stdev_A_logg5_plog = (combined_list[7])[i-2]\n",
    "            \n",
    "            # check that fitting numbers are retained\n",
    "            if (i == 2 and key != '5.0'):\n",
    "                print 'Exponential fit coefficients (should be reused): '\n",
    "                print exp_fit_A_logg5\n",
    "                print 'Standard deviations (should be reused): '\n",
    "                print stdev_A_logg5_ef\n",
    "\n",
    "                print 'Teff^(n) fit coefficients (should be reused): '\n",
    "                print pow_fit_A_logg5\n",
    "                print 'Standard deviations (should be reused): '\n",
    "                print stdev_A_logg5_pow\n",
    "\n",
    "                print 'Logistic fit coefficients: '\n",
    "                print logis_fit_A_logg5\n",
    "                print 'Standard deviations: '\n",
    "                print stdev_A_logg5_logis\n",
    "                \n",
    "                print 'Teff log-normal fit coefficients: '\n",
    "                print plog_fit_A_logg5\n",
    "                print 'Standard deviations: '\n",
    "                print stdev_A_logg5_plog\n",
    "                \n",
    "                print 2*'\\n'\n",
    "            \n",
    "            \n",
    "            if (write_stuff == 'y' and key == '5.0' and metal == 'solar'):\n",
    "                avg_dict = {}\n",
    "                with open (data_dir_str_i,'a') as f:\n",
    "                    print '\\n    Writing log(g)=' + key + ', Z = ' + metal + ' model for ' + filter_str[i-2] + ' filter'\n",
    "                    general_fit_number_gen_write(f,fit_types[0],exp_fit_A_logg5, stdev_A_logg5_ef,filter_str[i-2],float(key),avg_dict)\n",
    "                    general_fit_number_gen_write(f,fit_types[1],pow_fit_A_logg5, stdev_A_logg5_pow,filter_str[i-2],float(key),avg_dict)\n",
    "                    #general_fit_number_gen_write(f,fit_types[2],logis_fit_A_logg5, stdev_A_logg5_logis,filter_str[i-2],float(key),avg_dict)\n",
    "                    #general_fit_number_gen_write(f,fit_types[3],plog_fit_A_logg5, stdev_A_logg5_plog,filter_str[i-2],float(key),avg_dict)\n",
    "\n",
    "                    # write results of comparison of averages\n",
    "                    sorted_avg = sorted(avg_dict.items(), key=operator.itemgetter(1))\n",
    "                    f.write('RANKED MEAN FRACTIONAL ERRORS (best to worst) :   ' + '\\n')\n",
    "                    for j in sorted_avg:\n",
    "                        f.write(\"{: <40}\".format(str(j[0])) + 2*'\\t' + str(j[1]) + '\\n')\n",
    "                    f.close()\n",
    "                    #_0.02\n",
    "                \n",
    "            axs[i-2].set_xlabel(var_names_comb[0])\n",
    "            axs[i-2].set_ylabel(var_names_comb[i])\n",
    "            # - 0.01 (data - 0.01) *max(A_X_chosen[:,i])*max(data)\n",
    "            # + 0.01 (data + 0.01) *max(A_X_chosen[:,i])*max(data)\n",
    "            if (plot_diff == 'y'):\n",
    "                axs[i-2].axhline(y=0,color='k',label='Data')\n",
    "                axs[i-2].axhline(y=-sig_val,color='k',linestyle='--',label='Data lower accuracy limit (data - '+str(sig_val)+')')\n",
    "                axs[i-2].axhline(y=sig_val,color='k',linestyle='--',label='Data upper accuracy limit (data + '+str(sig_val)+')')\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - 0.02),'k',linestyle='-.',label='Data lower accuracy limit (data - 0.02)')\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] + 0.02),'k',linestyle='-.',label='Data upper accuracy limit (data + 0.02)')\n",
    "                axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - exp_func(A_X_chosen[:,0],*exp_fit_A_logg5)),'m',marker='x',label=fit_types[0])\n",
    "                axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - single_poly(A_X_chosen[:,0],*pow_fit_A_logg5)),'g',marker='x',label=fit_types[1])\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - R1_logistic_func(A_X_chosen[:,0],*logis_fit_A_logg5)),'r',marker='x',label=fit_types[2])\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - R1_log_normal_func(A_X_chosen[:,0],*plog_fit_A_logg5)),'b',marker='x',label=fit_types[3])\n",
    "            else:\n",
    "                axs[i-2].plot(A_X_chosen[:,0],A_X_chosen[:,i],'k',marker='x',linestyle='',label='Data')\n",
    "                axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - sig_val),'k',linestyle='--',label='Data lower accuracy limit (data - '+str(sig_val)+')')\n",
    "                axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] + sig_val),'k',linestyle='--',label='Data upper accuracy limit (data + '+str(sig_val)+')')\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] - 0.02),'k',linestyle='-.',label='Data lower accuracy limit (data - 0.02)')\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],(A_X_chosen[:,i] + 0.02),'k',linestyle='-.',label='Data upper accuracy limit (data + 0.02)')\n",
    "                axs[i-2].plot(A_X_chosen[:,0],exp_func(A_X_chosen[:,0],*exp_fit_A_logg5),'m',label=fit_types[0])\n",
    "                axs[i-2].plot(A_X_chosen[:,0],single_poly(A_X_chosen[:,0],*pow_fit_A_logg5),'g',label=fit_types[1])\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],R1_logistic_func(A_X_chosen[:,0],*logis_fit_A_logg5),'r',label=fit_types[2])\n",
    "                #axs[i-2].plot(A_X_chosen[:,0],R1_log_normal_func(A_X_chosen[:,0],*plog_fit_A_logg5),'b',label=fit_types[3])\n",
    "            if (zoom_min is not None and zoom_max is not None and (max(A_X_chosen[:,0]) >= zoom_max)):\n",
    "                axs[i-2].set_xlim(zoom_min,zoom_max)\n",
    "            title_str = filter_str[i-2] + ' filter'\n",
    "            #axs[i-2].set_title(title_str, y=1.02)\n",
    "        if ( (len(A_X_chosen[0,:]) - 2) < (Nrows*Ncols) ):\n",
    "            print 'Deleting missing subplots - discrepancy between ' + str(len(A_X_chosen[0,:]) - 2) + ' and ' + str(Nrows*Ncols)\n",
    "            for d in range((len(A_X_chosen[0,:]) - 2),(Nrows*Ncols)):\n",
    "                fig.delaxes(axs[d])\n",
    "        \n",
    "        if (plot_diff == 'y'):\n",
    "            plot_dir_str_i = folder + '/' + graph_fold + '/diff_AHub_logg=' + key + '_' + metal + '_' + extras + '_Teff_fit_plot'+coef_cut+'.pdf'\n",
    "        else:\n",
    "            plot_dir_str_i = folder + '/' + graph_fold + '/AHub_logg=' + key + '_' + metal + '_' + extras + '_Teff_fit_plot'+coef_cut+'.pdf'\n",
    "\n",
    "        sup_title_str = 'Extinction plots for log(g) = ' + key + ', Z = Z' + metal\n",
    "        #fig.suptitle(sup_title_str,size=16)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.92) # 0.88\n",
    "        plt.show()\n",
    "        if(save_stuff == 'y'):\n",
    "            fig.savefig(plot_dir_str_i, bbox_inches='tight')\n",
    "\n",
    "    else:\n",
    "        # Iteration for changes BETWEEN filters !!!\n",
    "        # i.e., should produce 3 versions of each output each time the function is called\n",
    "        for i in range(2,len(A_X_chosen[0,:])):\n",
    "            # empty directory string - avoid potential concatonation\n",
    "            plot_dir_str_i = None\n",
    "            data_dir_str_i = None\n",
    "            # curve-fitting commands\n",
    "            exp_fit_A_logg5 = (combined_list[0])[i-2]\n",
    "            stdev_A_logg5_ef = (combined_list[1])[i-2]\n",
    "            pow_fit_A_logg5 = (combined_list[2])[i-2]\n",
    "            stdev_A_logg5_pow = (combined_list[3])[i-2]\n",
    "            logis_fit_A_logg5 = (combined_list[4])[i-2]\n",
    "            stdev_A_logg5_logis = (combined_list[5])[i-2]\n",
    "\n",
    "            # check that fitting numbers are retained\n",
    "            if (i == 2):\n",
    "                print 'Exponential fit coefficients (should be reused): '\n",
    "                print exp_fit_A_logg5\n",
    "                print 'Standard deviations (should be reused): '\n",
    "                print stdev_A_logg5_ef\n",
    "\n",
    "                print 'Teff^(n) fit coefficients (should be reused): '\n",
    "                print pow_fit_A_logg5\n",
    "                print 'Standard deviations (should be reused): '\n",
    "                print stdev_A_logg5_pow\n",
    "\n",
    "                #print 'Logistic fit coefficients: '\n",
    "                #print logis_fit_A_logg5\n",
    "                #print 'Standard deviations: '\n",
    "                #print stdev_A_logg5_logis\n",
    "                \n",
    "                print 2*'\\n'\n",
    "\n",
    "            # Construct directories, files to save plots,data - i.e. construct strings\n",
    "            # String format should be: 'gaia_spectra/gaia_graphs/AGrp_logg=5.0_Teff_fit_plot.pdf' (example case)\n",
    "            if (casa_opt == 'y' and i == 2):\n",
    "                folder += '_casa'\n",
    "                graph_fold += '_casa'\n",
    "\n",
    "            plot_dir_str_i = folder + '/' + graph_fold + '/A' + filter_str[i-2] + '_logg=' + key + '_' + metal + '_' + extras + '_Teff_fit_plot'\n",
    "            data_dir_str_i = folder + '/Teff_A' + filter_str[i-2] + '_gen_fit_logg=' + key + '_' + metal + '_' + extras + '_numbers'\n",
    "            # separate Casagrande data\n",
    "            if (casa_opt == 'y'): # and i == 2\n",
    "                plot_dir_str_i += '_casa'\n",
    "                data_dir_str_i += '_casa'\n",
    "            plot_dir_str_i += '.pdf'\n",
    "            data_dir_str_i += '.txt'\n",
    "            \n",
    "            # plot commands\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.set_xlabel(var_names[0])\n",
    "            ax.set_ylabel(var_names[i])\n",
    "            if (casa_opt == 'y'):\n",
    "                ax.plot(A_X_chosen[:,0],A_X_chosen[:,i],'k',marker='x',linestyle='-',label='Data')\n",
    "                ax.plot(A_X_chosen[:,0],(A_X_chosen[:,i] - 0.01),'k',linestyle='-.',label='Data lower accuracy limit (data - 0.01)')\n",
    "                ax.plot(A_X_chosen[:,0],(A_X_chosen[:,i] + 0.01),'k',linestyle='--',label='Data upper accuracy limit (data + 0.01)')\n",
    "                ax.plot(casa_chosen[:,0],casa_chosen[:,i],'b',marker='x',linestyle='-',label='Casagrande data')\n",
    "                if (zoom_min is not None and zoom_max is not None):\n",
    "                    ax.set_xlim(zoom_min,zoom_max)\n",
    "            else:\n",
    "                # - 0.01 (data - 0.01) *max(A_X_chosen[:,i])*max(data)\n",
    "                # + 0.01 (data + 0.01) *max(A_X_chosen[:,i])*max(data)\n",
    "                ax.plot(A_X_chosen[:,0],A_X_chosen[:,i],'k',marker='x',linestyle='',label='Data')\n",
    "                ax.plot(A_X_chosen[:,0],(A_X_chosen[:,i] - 0.01),'k',linestyle='-.',label='Data lower accuracy limit (data - 0.01)')\n",
    "                ax.plot(A_X_chosen[:,0],(A_X_chosen[:,i] + 0.01),'k',linestyle='--',label='Data upper accuracy limit (data + 0.01)')\n",
    "                ax.plot(A_X_chosen[:,0],exp_func(A_X_chosen[:,0],*exp_fit_A_logg5),'m',label=fit_types[0])\n",
    "                ax.plot(A_X_chosen[:,0],single_poly(A_X_chosen[:,0],*pow_fit_A_logg5),'g',label=fit_types[1])\n",
    "                #ax.plot(A_X_chosen[:,0],R1_logistic_func(A_X_chosen[:,0],*logis_fit_A_logg5),'r',label=fit_types[2])\n",
    "                #ax.plot(A_X_chosen[:,0],R1_log_normal_func(A_X_chosen[:,0],*plog_fit_A_logg5),'b',label=fit_types[3])\n",
    "                if (zoom_min is not None and zoom_max is not None):\n",
    "                    ax.set_xlim(zoom_min,zoom_max)\n",
    "            \n",
    "            plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "            plt.show()\n",
    "            if (save_stuff == 'y'):\n",
    "                fig.savefig(plot_dir_str_i, bbox_inches='tight')\n",
    "\n",
    "            # data file write commands\n",
    "            \n",
    "            avg_dict = {}\n",
    "            if (write_stuff == 'y'):\n",
    "                with open (data_dir_str_i,'w') as f:\n",
    "                    print '\\n    Writing log(g)=' + key + ', Z = ' + metal + ' model'\n",
    "                    general_fit_number_gen_write(f,fit_types[0],exp_fit_A_logg5, stdev_A_logg5_ef,filter_str[i-2],float(key),avg_dict)\n",
    "                    general_fit_number_gen_write(f,fit_types[1],pow_fit_A_logg5, stdev_A_logg5_pow,filter_str[i-2],float(key),avg_dict)\n",
    "                    #general_fit_number_gen_write(f,fit_types[2],logis_fit_A_logg5, stdev_A_logg5_logis,filter_str[i-2],float(key),avg_dict)\n",
    "                    #general_fit_number_gen_write(f,fit_types[3],plog_fit_A_logg5, stdev_A_logg5_plog,filter_str[i-2],float(key),avg_dict)\n",
    "\n",
    "                    # write results of comparison of averages\n",
    "                    sorted_avg = sorted(avg_dict.items(), key=operator.itemgetter(1))\n",
    "                    f.write('RANKED MEAN FRACTIONAL ERRORS (best to worst) :   \\n')\n",
    "                    for j in sorted_avg:\n",
    "                        f.write(\"{: <40}\".format(str(j[0])) + 2*'\\t' + str(j[1]) + '\\n')\n",
    "                    f.close()\n",
    "\n",
    "                #with open (folder + '/coeffs_summary_cas.txt','a') as sf:\n",
    "                    #sf.write('Fit coefficients summary')\n",
    "                    #sf.write('log(g) = ' + key + ', Z = ' + metal + ', ' + filter_str[i-2] + ' filter ' + 3*'\\t' + str(pow_fit_A_logg5) + '\\n')\n",
    "                #sf.close()\n",
    "            print 'Writing complete for ' + filter_str[i-2] + ' filter'\n",
    "    print '\\n    Writing complete for log(g) = ' + key + ', Z = ' + metal + ' configuration, END OF FUNCTION WRITING!!!'\n",
    "\n",
    "def combine_filter_systems_dict(Afirst,Asecond):\n",
    "    comb_dict = {}\n",
    "    for key in sorted(Afirst.iterkeys()):\n",
    "        #print key\n",
    "        first_arr = Afirst[key]\n",
    "        second_arr = Asecond[key]\n",
    "        nfilters_second = (len(second_arr[0,:]) - 2)\n",
    "\n",
    "        comb_arr = np.zeros((len(first_arr[:,0]),(len(first_arr[0,:]) + nfilters_second)))\n",
    "        comb_arr[:,:-nfilters_second] = np.copy(first_arr)\n",
    "        comb_arr[:,-nfilters_second:] = np.copy(second_arr[:,2:len(second_arr[0,:])])\n",
    "        #comb_arr_zs = np.append(first_arr_zs,second_arr_zs[:,2:5])\n",
    "        comb_dict[key] = comb_arr\n",
    "        #print nfilters_second,len(comb_arr[0,:])\n",
    "    return comb_dict\n",
    "\n",
    "# extract coefficients into a summary file\n",
    "def make_coeffs_summary(directory,infile,outfile,filter_names,logg_val,metal,writing_type):\n",
    "    locin = directory + infile\n",
    "    locout = directory + outfile\n",
    "\n",
    "    with open(locin,'r') as inputf, open(locout,writing_type) as outputf:\n",
    "        n = 0\n",
    "        copy_bool = False\n",
    "        #outputf.write('Coefficients for Teff power law: \\n\\n')\n",
    "        #if (n <= (len(filter_names)-1)):\n",
    "        #copy_bool = False\n",
    "        for line in inputf:\n",
    "            #if ('Fitting results for' in line.strip()): == '    Covariance matrix:'\n",
    "                #outputf.write(line)\n",
    "            if (line.strip() == 'Function type:  Power law of Teff, fitted'):\n",
    "                copy_bool = True\n",
    "                n += 1\n",
    "            elif ('Covariance' in line.strip()):\n",
    "                copy_bool = False\n",
    "            elif copy_bool:\n",
    "                if ('Fit coefficients (in order of functions arguments)' in line.strip()):\n",
    "                    continue\n",
    "                else:\n",
    "                    print n\n",
    "                    outputf.write(filter_names[n-1] + ' filter, with  log(g) = ' + logg_val + ' and Z = Z' + metal + ': \\t\\t' + line)\n",
    "                    \n",
    "\n",
    "        outputf.write('#\\n#\\n')\n",
    "        inputf.close()\n",
    "        outputf.close()\n",
    "\n",
    "# Cutoff - tailflick evasion for fixed-log(g) dictionaries\n",
    "def Teff_cutoff_fix_logg_dict(old_dict,criterion):\n",
    "    new_dict = {}\n",
    "    x = 0\n",
    "    print 'Cutoff - tailflick evasion for fixed-log(g) dictionaries'\n",
    "    for key in sorted(old_dict.iterkeys()):\n",
    "        temp_arr_list = []\n",
    "        #print new_dict[key].shape\n",
    "        for i in range(len(old_dict[key][:,0])):\n",
    "            if (old_dict[key][i,0] >= criterion):\n",
    "                temp_arr_list.append(old_dict[key][i,:])\n",
    "                #print 'Teff value too low: ',new_dict[key][i,0]\n",
    "            elif(x == 0 and old_dict[key][i,0] < criterion):\n",
    "                print old_dict[key][i,0]\n",
    "        new_dict[key] = np.array(temp_arr_list)\n",
    "        x += 1\n",
    "    print x\n",
    "    return new_dict\n",
    "\n",
    "# High-Teff cutoff for log(g) effect modelling for fixed-Teff dictionaries\n",
    "def Teff_cutoff_fix_Teff_dict(old_dict,lower_lim,upper_lim=50000.0):\n",
    "    new_dict = {}\n",
    "    #print 'High-Teff cutoff for log(g) effect modelling for fixed-Teff dictionaries'\n",
    "    \n",
    "    for key in sorted(old_dict.iterkeys()):\n",
    "        float_key_val = float(key)\n",
    "        #print float_key_val\n",
    "        if (lower_lim <= float_key_val <= upper_lim):\n",
    "            new_dict[key] = old_dict[key]\n",
    "            #print float_key_val\n",
    "            \n",
    "    print 'Dictionary size (number of Teff values, full dictionary then cutoff-limited): '\n",
    "    print len(old_dict),len(new_dict)\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "# function to generate difference dictionaries, with arrays of varying log(g) for fitting (Teff-value keys)\n",
    "def diff_from_ref_Teff_key(input_dict,Teff_max_lim=None):\n",
    "    out_dict = {}\n",
    "    for key in sorted(input_dict.iterkeys()):\n",
    "        if (Teff_max_lim is not None and float(key) <= Teff_max_lim):\n",
    "            holder_arr = (input_dict[key])\n",
    "            i_list = []\n",
    "            for i in range(len(holder_arr[:,0])): # iterate over rows\n",
    "                j_list = []\n",
    "                for j in range(len(holder_arr[0,:])): # iterate over columns in row\n",
    "                    if (j==0 or j==1):\n",
    "                        j_val = holder_arr[i,j]\n",
    "                    else:\n",
    "                        j_val = (holder_arr[i,j] - holder_arr[-1,j])\n",
    "                    j_list.append(j_val)\n",
    "                i_list.append(j_list)\n",
    "            out_dict[key] = np.array(i_list)\n",
    "            #print 'Teff cut check for key = '+key,out_dict[key].shape\n",
    "            # current layout: only difference values for Teff < Teff_max_lim\n",
    "    return out_dict\n",
    "\n",
    "# function to generate difference dictionaries, with arrays of varying Teff for fitting (log(g) values as keys, same as final plot format)\n",
    "def diff_from_ref_logg_key(input_dict,R1_sim_dict,Teff_max_lim=None,ref_sim_yn='n'):\n",
    "    out_dict = {}\n",
    "    for key in sorted(input_dict.iterkeys()):\n",
    "        holder_arr = input_dict[key]\n",
    "        # ref_sim_yn indicates whether the reference dictionary to be used is a dictionary of data\n",
    "        # generated using the R1 coefficients or the dictionary's own data using log(g)=5.0\n",
    "        if (ref_sim_yn == 'n'):\n",
    "            ref_arr = input_dict['5.0']\n",
    "        else:\n",
    "            ref_arr = R1_sim_dict[key]\n",
    "        i_list = []\n",
    "        for i in range(len(holder_arr[:,0])): # iterate over rows\n",
    "            if (Teff_max_lim is not None and holder_arr[i,0] <= Teff_max_lim):\n",
    "                j_list = []\n",
    "                for j in range(len(holder_arr[0,:])): # iterate over columns in row\n",
    "                    if (j==0 or j==1):\n",
    "                        j_val = holder_arr[i,j]\n",
    "                    else:\n",
    "                        j_val = (holder_arr[i,j] - ref_arr[i,j])\n",
    "                    j_list.append(j_val)\n",
    "                i_list.append(j_list)\n",
    "        if (i_list != []):\n",
    "            out_dict[key] = np.array(i_list)\n",
    "            #print 'Teff cut check for key = '+key,out_dict[key].shape\n",
    "    return out_dict\n",
    "\n",
    "# for Teff-only functions, create dictionary to store data from results of round 1 coefficient fitting\n",
    "def make_sim_Teff_R1_array(input_dict,best_fits_filterwise):\n",
    "    out_dict = {}\n",
    "    for key in sorted(input_dict.iterkeys()):\n",
    "        holder_arr = np.copy(input_dict[key])\n",
    "        i_list = []\n",
    "        for i in range(len(holder_arr[:,0])): # iterate over rows\n",
    "            j_list = []\n",
    "            for j in range(len(holder_arr[0,:])): # iterate over columns in row\n",
    "                if (j==0 or j==1):\n",
    "                    j_val = holder_arr[i,j]\n",
    "                else:\n",
    "                    if (best_fits_filterwise[j-2] == 'exp'):\n",
    "                        j_val = exp_func(holder_arr[i,0], *exp_Teff_coef_4500K_logg_5[j-2])\n",
    "                    elif (best_fits_filterwise[j-2] == 'plpe'):\n",
    "                        j_val = full_pow_plus_exp_func(holder_arr[i,0], *plpe_Teff_coef_4500K_logg_5[j-2])\n",
    "                    else: # treat 'pow' as the standard\n",
    "                        j_val = single_poly(holder_arr[i,0], *pow_Teff_coef_4500K_logg_5[j-2])\n",
    "                j_list.append(j_val)\n",
    "            i_list.append(j_list)\n",
    "        out_dict[key] = np.array(i_list)\n",
    "    return out_dict\n",
    "\n",
    "print 'functions, modules done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6 3.1 5.6\n",
      "0.384615384615 0.322580645161 0.178571428571\n"
     ]
    }
   ],
   "source": [
    "# list of line-of-sight Rv values for the sources listed in Cardelli et al. (1989)\n",
    "Rv_list_CCM89 = [2.85,3.42,5.60,5.50,5.23,5.10,4.11,5.30,3.12,3.52,3.39,3.92,4.98,4.04,4.13,4.20,4.34,3.09,3.15,\\\n",
    "                 5.30,3.48,3.05,2.60,3.12,3.33,2.75,4.17,2.84,3.71,3.33]\n",
    "\n",
    "print min(Rv_list_CCM89),3.1,max(Rv_list_CCM89)\n",
    "print 1.0/min(Rv_list_CCM89),1.0/3.1,1.0/max(Rv_list_CCM89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B.: using cgs unit\n",
    "\n",
    "# FEBRUARY 2019: isochrone data cell\n",
    "# REMEMBER!: cgs units!!!\n",
    "\n",
    "basti_isochrones_dict_acs = {}\n",
    "basti_isochrones_dict_wfc3 = {}\n",
    "basti_isochrones_dict_gaia2 = {}\n",
    "this_metal = 0\n",
    "files_count = 0\n",
    "\n",
    "# Read in the BaSTI data files from the directory DIRECTLY into a dictionary\n",
    "dir_basti = os.listdir('basti_isochrones_10_13Gyr/')\n",
    "check_found_age = 0\n",
    "\n",
    "for isoc_f in dir_basti:\n",
    "    find_isoc_age = re.search('(.*)z0',isoc_f)\n",
    "    if find_isoc_age:\n",
    "        check_found_age += 1\n",
    "        isoc_age_val = find_isoc_age.group(1)\n",
    "        print isoc_age_val\n",
    "        # Gaia files/filters\n",
    "        if 'gaia' in isoc_f:\n",
    "            print 'gaia file:',isoc_f\n",
    "            with open('basti_isochrones_10_13Gyr/'+isoc_f,'r') as gaia2_basti_file:\n",
    "                temp_store_gaia2,zval_gaia2 = data_read_basti_isochrone(gaia2_basti_file)\n",
    "                gaia2_basti_file.close()\n",
    "            basti_isochrones_dict_gaia2[str(isoc_age_val)+','+str(zval_gaia2)] = temp_store_gaia2\n",
    "        # WFC3 files/filters    \n",
    "        elif 'wfc3' in isoc_f:\n",
    "            print 'wfc3 file:',isoc_f\n",
    "            with open('basti_isochrones_10_13Gyr/'+isoc_f,'r') as wfc3_basti_file:\n",
    "                temp_store_wfc3,zval_wfc3 = data_read_basti_isochrone(wfc3_basti_file)\n",
    "                wfc3_basti_file.close()\n",
    "            basti_isochrones_dict_wfc3[str(isoc_age_val)+','+str(zval_wfc3)] = temp_store_wfc3\n",
    "        # ACS files/filters    \n",
    "        elif 'acs' in isoc_f:\n",
    "            print 'acs file:',isoc_f\n",
    "            with open('basti_isochrones_10_13Gyr/'+isoc_f,'r') as acs_basti_file:\n",
    "                temp_store_acs,zval_acs = data_read_basti_isochrone(acs_basti_file)\n",
    "                acs_basti_file.close()\n",
    "            basti_isochrones_dict_acs[str(isoc_age_val)+','+str(zval_acs)] = temp_store_acs\n",
    "\n",
    "# change nummpy print options from default\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "print 'Gaia data read '\n",
    "print '\\n'\n",
    "\n",
    "dir_str = os.listdir('Rv_varied/')\n",
    "\n",
    "def folder_read_in(dir_str,):\n",
    "    all_folder_dict = {}\n",
    "    for atmos_file in dir_str:\n",
    "        find_Rv_val = re.search('_Rv(.*)',atmos_file)\n",
    "        # ACS\n",
    "        if 'ACS_OUTPUT' in atmos_file:\n",
    "            print 'acs file:', atmos_file\n",
    "        # WFC3\n",
    "        elif 'H_OUTPUT' in atmos_file:\n",
    "            print 'wfc3 file:', atmos_file\n",
    "        # Gaia (all other files)\n",
    "        else:\n",
    "            print 'gaia file:', atmos_file\n",
    "            \n",
    "\"\"\"\n",
    "print 'Found ages for ' + str(check_found_age) + ' out of ' + str(len(dir_basti)) + ' files in directory'\n",
    "print len(basti_isochrones_dict_acs),len(basti_isochrones_dict_wfc3),len(basti_isochrones_dict_gaia2)\n",
    "\n",
    "for key in sorted(basti_isochrones_dict_gaia2.iterkeys()):\n",
    "    print key\n",
    "print 'Isochrone data loaded, keys printed above'\n",
    "# DEFAULT numpy print settings\n",
    "#np.set_printoptions(edgeitems=3,infstr='inf',linewidth=75, nanstr='nan', precision=8,suppress=False, \\\n",
    "#                    threshold=1000, formatter=None)\n",
    "\n",
    "\"\"\"\n",
    "# Gaia output\n",
    "# Solar metallicity, Zsolar\n",
    "with open (folder_str+\"/OUTPUT_Av0_zsolar\",\"r\") as Av0zs:\n",
    "    print '\\n    Reading A(v) = 0, Z = Zsolar model'\n",
    "    Av0zs_data = data_read_gaia(Av0zs)\n",
    "    Av0zs.close()\n",
    "\n",
    "with open (folder_str+\"/OUTPUT_Av1_zsolar\",\"r\") as Av1zs:\n",
    "    print '\\n    Reading A(v) = 1, Z = Zsolar model'\n",
    "    Av1zs_data = data_read_gaia(Av1zs)\n",
    "    Av1zs.close()\n",
    "    \n",
    "# Zsolar/100\n",
    "with open (folder_str+\"/OUTPUT_Av0_z10-2\",\"r\") as Av0z2:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(-2) Zsolar) model'\n",
    "    Av0z2_data = data_read_gaia(Av0z2)\n",
    "    Av0z2.close()\n",
    "      \n",
    "with open (folder_str+\"/OUTPUT_Av1_z10-2\",\"r\") as Av1z2:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(-2) Zsolar) model'\n",
    "    Av1z2_data = data_read_gaia(Av1z2)\n",
    "    Av1z2.close()\n",
    "    \n",
    "# Zsolar/10\n",
    "with open (folder_str+\"/OUTPUT_Av0_z10-1\",\"r\") as Av0z1:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(-1) Zsolar) model'\n",
    "    Av0z1_data = data_read_gaia(Av0z1)\n",
    "    Av0z1.close()\n",
    "      \n",
    "with open (folder_str+\"/OUTPUT_Av1_z10-1\",\"r\") as Av1z1:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(-1) Zsolar) model'\n",
    "    Av1z1_data = data_read_gaia(Av1z1)\n",
    "    Av1z1.close()\n",
    "\n",
    "# Zsolar*3 (really *10^0.5 = 3.162)\n",
    "with open (folder_str+\"/OUTPUT_Av0_z10+half\",\"r\") as Av0zh:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(0.5) Zsolar) model'\n",
    "    Av0zh_data = data_read_gaia(Av0zh)\n",
    "    Av0zh.close()\n",
    "      \n",
    "with open (folder_str+\"/OUTPUT_Av1_z10+half\",\"r\") as Av1zh:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(0.5) Zsolar) model'\n",
    "    Av1zh_data = data_read_gaia(Av1zh)\n",
    "    Av1zh.close()\n",
    "\n",
    "# dictionaries (Cardelli et al. Rv = 3.1)\n",
    "# Note: Teff is column 1, log(g) is column 2\n",
    "print '****Creating arrays****'\n",
    "print '****Separating data into arrays by log(g) values****'\n",
    "\n",
    "# Zsolar\n",
    "Av0zs_logg_fix,Av0zs_logg_vals = grid_vals_dict(Av0zs_data,2)\n",
    "Av1zs_logg_fix,Av1zs_logg_vals = grid_vals_dict(Av1zs_data,2)\n",
    "# Zsolar/100\n",
    "Av0z2_logg_fix,Av0z2_logg_vals = grid_vals_dict(Av0z2_data,2)\n",
    "Av1z2_logg_fix,Av1z2_logg_vals = grid_vals_dict(Av1z2_data,2)\n",
    "# Zsolar/10\n",
    "Av0z1_logg_fix,Av0z1_logg_vals = grid_vals_dict(Av0z1_data,2)\n",
    "Av1z1_logg_fix,Av1z1_logg_vals = grid_vals_dict(Av1z1_data,2)\n",
    "# Zsolar*3\n",
    "Av0zh_logg_fix,Av0zh_logg_vals = grid_vals_dict(Av0zh_data,2)\n",
    "Av1zh_logg_fix,Av1zh_logg_vals = grid_vals_dict(Av1zh_data,2)\n",
    "\n",
    "\n",
    "print '****Separating data into arrays by Teff values****'\n",
    "\n",
    "# Zsolar\n",
    "Av0zs_Teff_fix,Av0zs_Teff_vals = grid_vals_dict(Av0zs_data,1)\n",
    "Av1zs_Teff_fix,Av1zs_Teff_vals = grid_vals_dict(Av1zs_data,1)\n",
    "# Zsolar/100\n",
    "Av0z2_Teff_fix,Av0z2_Teff_vals = grid_vals_dict(Av0z2_data,1)\n",
    "Av1z2_Teff_fix,Av1z2_Teff_vals = grid_vals_dict(Av1z2_data,1)\n",
    "# Zsolar/10\n",
    "Av0z1_Teff_fix,Av0z1_Teff_vals = grid_vals_dict(Av0z1_data,1)\n",
    "Av1z1_Teff_fix,Av1z1_Teff_vals = grid_vals_dict(Av1z1_data,1)\n",
    "# Zsolar*3\n",
    "Av0zh_Teff_fix,Av0zh_Teff_vals = grid_vals_dict(Av0zh_data,1)\n",
    "Av1zh_Teff_fix,Av1zh_Teff_vals = grid_vals_dict(Av1zh_data,1)\n",
    "\n",
    "print '****Finished arrays****'\n",
    "\n",
    "# Final input data form: Ax/Av extinction ratios\n",
    "Agaia_zs = diff_grid_dict(Av0zs_logg_fix,Av1zs_logg_fix)\n",
    "Agaia_z2 = diff_grid_dict(Av0z2_logg_fix,Av1z2_logg_fix)\n",
    "Agaia_z1 = diff_grid_dict(Av0z1_logg_fix,Av1z1_logg_fix)\n",
    "Agaia_zh = diff_grid_dict(Av0zh_logg_fix,Av1zh_logg_fix)\n",
    "\n",
    "Agaia_zs_Teff_fix = diff_grid_dict(Av0zs_Teff_fix,Av1zs_Teff_fix)\n",
    "Agaia_z2_Teff_fix = diff_grid_dict(Av0z2_Teff_fix,Av1z2_Teff_fix)\n",
    "Agaia_z1_Teff_fix = diff_grid_dict(Av0z1_Teff_fix,Av1z1_Teff_fix)\n",
    "Agaia_zh_Teff_fix = diff_grid_dict(Av0zh_Teff_fix,Av1zh_Teff_fix)\n",
    "\n",
    "var_names = ['$T_{eff}$ / K','log($g$ / cm s$^{-2}$)','$A(G)/A(V)$','$A(G_{bp})/A(V)$','$A(G_{rp})/A(V)$','log($T_{eff}$ / K)']\n",
    "\n",
    "# strings describing functions being fitted to the data\n",
    "fit_types = []\n",
    "\n",
    "fit_types.append('Exponential function of Teff, fitted')\n",
    "fit_types.append('Power law of Teff, fitted')\n",
    "#fit_types.append('Power law + exponential function of Teff, fitted')\n",
    "fit_types.append('Logistic function of Teff, fitted')\n",
    "fit_types.append('Log-normal function of Teff, fitted')\n",
    "\n",
    "# strings describing functions being fitted to the data FOR LOG(G)!\n",
    "logg_fit_types = []\n",
    "\n",
    "logg_fit_types.append('Quadratic in log(g), fitted')\n",
    "\n",
    "product_fits = []\n",
    "product_fits.append('Exponential function of Teff, fitted, plus Teff-log(g) product corrections')\n",
    "product_fits.append('Power law of Teff, fitted, plus Teff-log(g) product corrections')\n",
    "product_fits.append('Power law + exponential function of Teff, fitted, plus Teff-log(g) product corrections')\n",
    " \n",
    "print 'Variable data arrays organized'\n",
    "\n",
    "# N.B.: using cgs unit\n",
    "print 'WFC3 Hubble data read'\n",
    "print '\\n'\n",
    "\n",
    "# Zsolar\n",
    "with open (folder_str+\"/H_OUTPUT_Av0_zsolar\") as Av0zs:\n",
    "    print '\\n    Reading A(v) = 0, Z = Zsolar model'\n",
    "    Av0zs_hub_data = data_read_gaia(Av0zs)\n",
    "    Av0zs.close()\n",
    "\n",
    "with open (folder_str+\"/H_OUTPUT_Av1_zsolar\") as Av1zs:\n",
    "    print '\\n    Reading A(v) = 1, Z = Zsolar model'\n",
    "    Av1zs_hub_data = data_read_gaia(Av1zs)\n",
    "    Av1zs.close()\n",
    "    \n",
    "# Zsolar/100\n",
    "with open (folder_str+\"/H_OUTPUT_Av0_z10-2\") as Av0z2:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(-2) Zsolar) model'\n",
    "    Av0z2_hub_data = data_read_gaia(Av0z2)\n",
    "    Av0z2.close()\n",
    "\n",
    "with open (folder_str+\"/H_OUTPUT_Av1_z10-2\") as Av1z2:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(-2) Zsolar) model'\n",
    "    Av1z2_hub_data = data_read_gaia(Av1z2)\n",
    "    Av1z2.close()\n",
    "    \n",
    "# Zsolar/10\n",
    "with open (folder_str+\"/H_OUTPUT_Av0_z10-1\") as Av0z1:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(-1) Zsolar) model'\n",
    "    Av0z1_hub_data = data_read_gaia(Av0z1)\n",
    "    Av0z1.close()\n",
    "\n",
    "with open (folder_str+\"/H_OUTPUT_Av1_z10-1\") as Av1z1:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(-1) Zsolar) model'\n",
    "    Av1z1_hub_data = data_read_gaia(Av1z1)\n",
    "    Av1z1.close()\n",
    "    \n",
    "# Zsolar*3 (really *10^0.5 = 3.162)\n",
    "with open (folder_str+\"/H_OUTPUT_Av0_z10+half\") as Av0zh:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(0.5) Zsolar) model'\n",
    "    Av0zh_hub_data = data_read_gaia(Av0zh)\n",
    "    Av0zh.close()\n",
    "\n",
    "with open (folder_str+\"/H_OUTPUT_Av1_z10+half\") as Av1zh:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(0.5) Zsolar) model'\n",
    "    Av1zh_hub_data = data_read_gaia(Av1zh)\n",
    "    Av1zh.close()\n",
    "\n",
    "    \n",
    "# Note: Teff is column 1, log(g) is column 2\n",
    "print '****Creating arrays****'\n",
    "print '****Separating data into arrays by log(g) values****'\n",
    "# dictionaries\n",
    "# Zsolar\n",
    "Av0zs_logg_fix,Av0zs_logg_vals = grid_vals_dict(Av0zs_hub_data,2)\n",
    "Av1zs_logg_fix,Av1zs_logg_vals = grid_vals_dict(Av1zs_hub_data,2)\n",
    "# Zsolar/100\n",
    "Av0z2_logg_fix,Av0z2_logg_vals = grid_vals_dict(Av0z2_hub_data,2)\n",
    "Av1z2_logg_fix,Av1z2_logg_vals = grid_vals_dict(Av1z2_hub_data,2)\n",
    "# Zsolar/10\n",
    "Av0z1_logg_fix,Av0z1_logg_vals = grid_vals_dict(Av0z1_hub_data,2)\n",
    "Av1z1_logg_fix,Av1z1_logg_vals = grid_vals_dict(Av1z1_hub_data,2)\n",
    "# Zsolar*3\n",
    "Av0zh_logg_fix,Av0zh_logg_vals = grid_vals_dict(Av0zh_hub_data,2)\n",
    "Av1zh_logg_fix,Av1zh_logg_vals = grid_vals_dict(Av1zh_hub_data,2)\n",
    "\n",
    "\n",
    "Ahub_zs = diff_grid_dict(Av0zs_logg_fix,Av1zs_logg_fix)\n",
    "Ahub_z2 = diff_grid_dict(Av0z2_logg_fix,Av1z2_logg_fix)\n",
    "Ahub_z1 = diff_grid_dict(Av0z1_logg_fix,Av1z1_logg_fix)\n",
    "Ahub_zh = diff_grid_dict(Av0zh_logg_fix,Av1zh_logg_fix)\n",
    "\n",
    "print '****Separating data into arrays by Teff values****'\n",
    "\n",
    "# Zsolar\n",
    "Av0zs_Teff_fix,Av0zs_Teff_vals = grid_vals_dict(Av0zs_hub_data,1)\n",
    "Av1zs_Teff_fix,Av1zs_Teff_vals = grid_vals_dict(Av1zs_hub_data,1)\n",
    "# Zsolar/100\n",
    "Av0z2_Teff_fix,Av0z2_Teff_vals = grid_vals_dict(Av0z2_hub_data,1)\n",
    "Av1z2_Teff_fix,Av1z2_Teff_vals = grid_vals_dict(Av1z2_hub_data,1)\n",
    "# Zsolar/10\n",
    "Av0z1_Teff_fix,Av0z1_Teff_vals = grid_vals_dict(Av0z1_hub_data,1)\n",
    "Av1z1_Teff_fix,Av1z1_Teff_vals = grid_vals_dict(Av1z1_hub_data,1)\n",
    "# Zsolar*3\n",
    "Av0zh_Teff_fix,Av0zh_Teff_vals = grid_vals_dict(Av0zh_hub_data,1)\n",
    "Av1zh_Teff_fix,Av1zh_Teff_vals = grid_vals_dict(Av1zh_hub_data,1)\n",
    "\n",
    "Ahub_zs_Teff_fix = diff_grid_dict(Av0zs_Teff_fix,Av1zs_Teff_fix)\n",
    "Ahub_z2_Teff_fix = diff_grid_dict(Av0z2_Teff_fix,Av1z2_Teff_fix)\n",
    "Ahub_z1_Teff_fix = diff_grid_dict(Av0z1_Teff_fix,Av1z1_Teff_fix)\n",
    "Ahub_zh_Teff_fix = diff_grid_dict(Av0zh_Teff_fix,Av1zh_Teff_fix)\n",
    "\n",
    "print '****Finished arrays****'\n",
    "\n",
    "# N.B.: using cgs unit\n",
    "print 'ACS Hubble data read'\n",
    "print '\\n'\n",
    "\n",
    "# Zsolar\n",
    "with open (folder_str+\"/ACS_OUTPUT_Av0_zsolar\") as Av0zs:\n",
    "    print '\\n    Reading A(v) = 0, Z = Zsolar model'\n",
    "    Av0zs_ACS_data = data_read_gaia(Av0zs)\n",
    "    Av0zs.close()\n",
    "\n",
    "with open (folder_str+\"/ACS_OUTPUT_Av1_zsolar\") as Av1zs:\n",
    "    print '\\n    Reading A(v) = 1, Z = Zsolar model'\n",
    "    Av1zs_ACS_data = data_read_gaia(Av1zs)\n",
    "    Av1zs.close()\n",
    "    \n",
    "# Zsolar/100\n",
    "with open (folder_str+\"/ACS_OUTPUT_Av0_z10-2\") as Av0z2:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(-2) Zsolar) model'\n",
    "    Av0z2_ACS_data = data_read_gaia(Av0z2)\n",
    "    Av0z2.close()\n",
    "\n",
    "with open (folder_str+\"/ACS_OUTPUT_Av1_z10-2\") as Av1z2:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(-2) Zsolar) model'\n",
    "    Av1z2_ACS_data = data_read_gaia(Av1z2)\n",
    "    Av1z2.close()\n",
    "    \n",
    "# Zsolar/10\n",
    "with open (folder_str+\"/ACS_OUTPUT_Av0_z10-1\") as Av0z1:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(-1) Zsolar) model'\n",
    "    Av0z1_ACS_data = data_read_gaia(Av0z1)\n",
    "    Av0z1.close()\n",
    "\n",
    "with open (folder_str+\"/ACS_OUTPUT_Av1_z10-1\") as Av1z1:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(-1) Zsolar) model'\n",
    "    Av1z1_ACS_data = data_read_gaia(Av1z1)\n",
    "    Av1z1.close()\n",
    "    \n",
    "# Zsolar*3 (really *10^0.5 = 3.162)\n",
    "with open (folder_str+\"/ACS_OUTPUT_Av0_z10+half\") as Av0zh:\n",
    "    print '\\n    Reading A(v) = 0, Z = (10^(0.5) Zsolar) model'\n",
    "    Av0zh_ACS_data = data_read_gaia(Av0zh)\n",
    "    Av0zh.close()\n",
    "\n",
    "with open (folder_str+\"/ACS_OUTPUT_Av1_z10+half\") as Av1zh:\n",
    "    print '\\n    Reading A(v) = 1, Z = (10^(0.5) Zsolar) model'\n",
    "    Av1zh_ACS_data = data_read_gaia(Av1zh)\n",
    "    Av1zh.close()\n",
    "\n",
    "    \n",
    "# Note: Teff is column 1, log(g) is column 2\n",
    "print '****Creating arrays****'\n",
    "print '****Separating data into arrays by log(g) values****'\n",
    "# dictionaries\n",
    "# Zsolar\n",
    "Av0zs_logg_fix,Av0zs_logg_vals = grid_vals_dict(Av0zs_ACS_data,2)\n",
    "Av1zs_logg_fix,Av1zs_logg_vals = grid_vals_dict(Av1zs_ACS_data,2)\n",
    "# Zsolar/100\n",
    "Av0z2_logg_fix,Av0z2_logg_vals = grid_vals_dict(Av0z2_ACS_data,2)\n",
    "Av1z2_logg_fix,Av1z2_logg_vals = grid_vals_dict(Av1z2_ACS_data,2)\n",
    "# Zsolar/10\n",
    "Av0z1_logg_fix,Av0z1_logg_vals = grid_vals_dict(Av0z1_ACS_data,2)\n",
    "Av1z1_logg_fix,Av1z1_logg_vals = grid_vals_dict(Av1z1_ACS_data,2)\n",
    "# Zsolar*3\n",
    "Av0zh_logg_fix,Av0zh_logg_vals = grid_vals_dict(Av0zh_ACS_data,2)\n",
    "Av1zh_logg_fix,Av1zh_logg_vals = grid_vals_dict(Av1zh_ACS_data,2)\n",
    "\n",
    "\n",
    "ACS_dict_zs = diff_grid_dict(Av0zs_logg_fix,Av1zs_logg_fix)\n",
    "ACS_dict_z2 = diff_grid_dict(Av0z2_logg_fix,Av1z2_logg_fix)\n",
    "ACS_dict_z1 = diff_grid_dict(Av0z1_logg_fix,Av1z1_logg_fix)\n",
    "ACS_dict_zh = diff_grid_dict(Av0zh_logg_fix,Av1zh_logg_fix)\n",
    "\n",
    "ACS_dict_zs_4500K = Teff_cutoff_fix_logg_dict(ACS_dict_zs,4500.0)\n",
    "ACS_dict_z2_4500K = Teff_cutoff_fix_logg_dict(ACS_dict_z2,4500.0)\n",
    "ACS_dict_z1_4500K = Teff_cutoff_fix_logg_dict(ACS_dict_z1,4500.0)\n",
    "ACS_dict_zh_4500K = Teff_cutoff_fix_logg_dict(ACS_dict_zh,4500.0)\n",
    "\n",
    "print '4500K cutoff ACS dict data shape: '\n",
    "for key in sorted(ACS_dict_zs_4500K.iterkeys()):\n",
    "    print ACS_dict_zs_4500K[key].shape\n",
    "\n",
    "print '****Finished arrays****'\n",
    "\n",
    "# combined (Hubble-WFC3 + Gaia) data dictionaries of arrays at fixed log(g) [default format!!!] and different fixed Z values\n",
    "comb_dict_zs = combine_filter_systems_dict(Ahub_zs,Agaia_zs)\n",
    "comb_dict_z2 = combine_filter_systems_dict(Ahub_z2,Agaia_z2)\n",
    "comb_dict_z1 = combine_filter_systems_dict(Ahub_z1,Agaia_z1)\n",
    "comb_dict_zh = combine_filter_systems_dict(Ahub_zh,Agaia_zh)\n",
    "\n",
    "# Avoid tailflick filter artifacts: need Teff cutoff!\n",
    "# log(g)-keyed dictionaries\n",
    "comb_dict_zs_4500K = Teff_cutoff_fix_logg_dict(comb_dict_zs,4500.0)\n",
    "comb_dict_z2_4500K = Teff_cutoff_fix_logg_dict(comb_dict_z2,4500.0)\n",
    "comb_dict_z1_4500K = Teff_cutoff_fix_logg_dict(comb_dict_z1,4500.0)\n",
    "comb_dict_zh_4500K = Teff_cutoff_fix_logg_dict(comb_dict_zh,4500.0)\n",
    "\n",
    "# write out array of combined Hubble & Gaia data\n",
    "#with open('Acombined_vals_solar_gfix','w') as f:\n",
    "#    for key in comb_dict_zs:\n",
    "#        f.write('log(g) = ' + key + ', Z=Zsol')\n",
    "#        f.write(comb_dict_zs[key])\n",
    "        \n",
    "        \n",
    "print type(comb_dict_zs),type(comb_dict_zs['0.0'])\n",
    "print comb_dict_zs['0.0'].shape\n",
    "print len(comb_dict_zs)\n",
    "\n",
    "print comb_dict_Teff_zs['5000.0'].shape\n",
    "print len(comb_dict_Teff_zs)\n",
    "\n",
    "var_names = ['$T_{eff}$ / K','log($g$ / cm s$^{-2}$)','$A(f218w)/A(V)$','$A(f225w)/A(V)$','$A(f275w)/A(V)$','$A(f300x)/A(V)$','$A(f336w)/A(V)$','$A(f390w)/A(V)$','$A(f438w)/A(V)$','$A(f475w)/A(V)$','$A(f555w)/A(V)$','$A(f606w)/A(V)$','$A(f625w)/A(V)$','$A(f775w)/A(V)$','$A(f814w)/A(V)$']\n",
    "\n",
    "# 'log($T_{eff}$ / K)'\n",
    "\n",
    "# filter string names\n",
    "wfc3_filter_str = ['f218w','f225w','f275w','f300x','f336w','f390w','f438w','f475w','f555w','f606w','f625w','f775w','f814w']\n",
    "gaia_filter_str = ['G','Gbp','Grp']\n",
    "comb_filter_str = wfc3_filter_str + gaia_filter_str\n",
    "\n",
    "var_names_comb = ['$T_{eff}$ / K','log($g$ / cm s$^{-2}$)','$A(f218w)/A(V)$','$A(f225w)/A(V)$','$A(f275w)/A(V)$',\\\n",
    "                  '$A(f300x)/A(V)$','$A(f336w)/A(V)$','$A(f390w)/A(V)$','$A(f438w)/A(V)$','$A(f475w)/A(V)$',\\\n",
    "                  '$A(f555w)/A(V)$','$A(f606w)/A(V)$','$A(f625w)/A(V)$','$A(f775w)/A(V)$','$A(f814w)/A(V)$',\\\n",
    "                  '$A(G)/A(V)$','$A(G_{bp})/A(V)$','$A(G_{rp})/A(V)$']\n",
    "var_names_ACS = ['$T_{eff}$ / K','log($g$ / cm s$^{-2}$)','$A(f435w)/A(V)$','$A(f475w)/A(V)$','$A(f555w)/A(V)$',\\\n",
    "                 '$A(f606w)/A(V)$','$A(f625w)/A(V)$','$A(f775w)/A(V)$','$A(f814w)/A(V)$']\n",
    "\n",
    "print '4500K cutoff combined dict data shape: '\n",
    "for key in sorted(comb_dict_zs_4500K.iterkeys()):\n",
    "    print comb_dict_zs_4500K[key].shape\n",
    "    \n",
    "#print '4000K cutoff dict data shape: '\n",
    "#for key in sorted(comb_dict_zs_4000K.iterkeys()):\n",
    "#    print comb_dict_zs_4000K[key].shape\n",
    "\n",
    "acs_filter_str = ['f435w ACS','f475w ACS','f555w ACS','f606w ACS','f625w ACS','f775w ACS','f814w ACS']\n",
    "print 'ACS filter labels length: ',len(acs_filter_str)\n",
    "\n",
    "print 'Variable data arrays organized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APRIL 2019: for thesis, just need data: no fits!\n",
    "# Change font sizes to makes figure legends and axes labels bigger\n",
    "# NOTE: 10 pt is the default standard font size\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=16)    # legend fontsize\n",
    "\n",
    "def just_fortran_data_plot(allZ_superdict,metal,var_names_comb,folder,graph_fold,extras='',save_stuff='y',zoom_min=None,zoom_max=None):\n",
    "    data_dict = allZ_superdict[metal]\n",
    "    metal = metal.replace('.','p')\n",
    "    if ('-' in metal):\n",
    "        metal = metal.replace('-','m')\n",
    "    if ( (zoom_min is not None) and (zoom_max is not None)):\n",
    "        plot_dir_str_metal = folder + '/' + graph_fold + '/AHub_FeH' + metal + '_just_Teff_plot_' + str(zoom_min) + '_' + str(zoom_max) + extras + '.pdf'\n",
    "    else:\n",
    "        plot_dir_str_metal = folder + '/' + graph_fold + '/AHub_FeH' + metal + '_just_Teff_plot' + extras + '.pdf'\n",
    "    if (len(data_dict['5.0'][0,:]) > 11):\n",
    "        fig, axs = plt.subplots(nrows=4,ncols=4,figsize=(16, 16))\n",
    "        Nrows = 4\n",
    "        Ncols = 4\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nrows=3,ncols=3,figsize=(16, 16))\n",
    "        Nrows = 3\n",
    "        Ncols = 3\n",
    "    axs = axs.ravel()\n",
    "    # Write out to new file: first 'with' statement empties the file to be written into later\n",
    "    # Iteration for changes BETWEEN filters !!!\n",
    "    for i in range(2,len(data_dict['5.0'][0,:])):\n",
    "        axs[i-2].set_xlabel(var_names_comb[0])\n",
    "        axs[i-2].set_ylabel(var_names_comb[i])\n",
    "        for keyval in reversed(sorted(data_dict.iterkeys())):\n",
    "            A_X_chosen = data_dict[keyval]\n",
    "            axs[i-2].plot(A_X_chosen[:,0],A_X_chosen[:,i],marker='',linestyle='-',label='log(g) = '+keyval)#,marker='x',linestyle='--'\n",
    "            if ( (zoom_min is not None) and (zoom_max is not None)):\n",
    "                axs[i-2].set_xlim(zoom_min,zoom_max)\n",
    "    if ( (len(data_dict['5.0'][0,:]) - 2) < (Nrows*Ncols) ):\n",
    "        print 'Deleting missing subplots - discrepancy between ' + str(len(data_dict['5.0'][0,:]) - 2) + ' and ' + str(Nrows*Ncols)\n",
    "        for d in range((len(data_dict['5.0'][0,:]) - 2),(Nrows*Ncols)):\n",
    "            fig.delaxes(axs[d])\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    if (save_stuff == 'y'):\n",
    "        fig.savefig(plot_dir_str_metal, bbox_inches='tight')\n",
    "\n",
    "comb_dict_allZ = {\n",
    "    '0.0' : comb_dict_zs,\n",
    "    '-2.0' : comb_dict_z2,\n",
    "    '-1.0' : comb_dict_z1,\n",
    "    '0.5' : comb_dict_zh\n",
    "}\n",
    "\n",
    "ACS_dict_allZ = {\n",
    "    '0.0' : ACS_dict_zs,\n",
    "    '-2.0' : ACS_dict_z2,\n",
    "    '-1.0' : ACS_dict_z1,\n",
    "    '0.5' : ACS_dict_zh\n",
    "}\n",
    "for zkey in comb_dict_allZ:\n",
    "    just_fortran_data_plot(comb_dict_allZ,zkey,var_names_comb,folder_str+'/just_full_data','comb',extras='_lines')#,zoom_min=3000,zoom_max=15000)\n",
    "    just_fortran_data_plot(ACS_dict_allZ,zkey,var_names_ACS,folder_str+'/just_full_data','ACS',extras='_lines')#,zoom_min=3000,zoom_max=15000)\n",
    "    #,save_stuff='n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
